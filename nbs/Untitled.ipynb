{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data  = []\n",
    "hyp_N = 2\n",
    "root_dir='/home/mprabhud/dataset/clevr_lang/npys/ab_5t.txt'\n",
    "with open(root_dir) as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "\n",
    "    for line in lines:\n",
    "        data.append(line.split()[0])\n",
    "        \n",
    "\n",
    "all_files = [os.path.join(os.path.dirname(root_dir),f) for f in data if f.endswith('.p')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "index = 10\n",
    "scene = 200\n",
    "# TODO ; add assert to return hyp-N boxes per image\n",
    "scene_path = all_files[scene]\n",
    "data = pickle.load(open(scene_path, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/lib64/libc.so.6: version `GLIBC_2.14' not found (required by /home/mprabhud/miniconda3/envs/disco/lib/python3.7/site-packages/torch/_C.cpython-37m-x86_64-linux-gnu.so)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-738e32d2598d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mToTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mprabhud/miniconda3/envs/disco/lib/python3.7/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0m_dl_flags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m __all__ += [name for name in dir(_C)\n",
      "\u001b[0;31mImportError\u001b[0m: /lib64/libc.so.6: version `GLIBC_2.14' not found (required by /home/mprabhud/miniconda3/envs/disco/lib/python3.7/site-packages/torch/_C.cpython-37m-x86_64-linux-gnu.so)"
     ]
    }
   ],
   "source": [
    "\n",
    "import collections, os, io\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision.transforms import ToTensor, Resize\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import pickle\n",
    "import core.utils_data as utils_disco\n",
    "import core.utils_vox as utils_vox\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = torch.as_tensor(data['rgb_camXs_raw']).permute(0,3,1,2)/255.\n",
    "# _, _, H_orig, W_orig = images.shape\n",
    "# query_image, key_image = images[0,:3,:,:], images[1,:3,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, axarr = plt.subplots(1,2)\n",
    "# axarr[0].imshow(query_image.permute(1,2,0))\n",
    "# axarr[1].imshow(key_image.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_B = 1\n",
    "hyp_S = 2\n",
    "\n",
    "__p = lambda x: utils_disco.pack_seqdim(x, hyp_B)\n",
    "__u = lambda x: utils_disco.unpack_seqdim(x, hyp_B)\n",
    "__pb = lambda x: utils_disco.pack_boxdim(x, hyp_N)\n",
    "__ub = lambda x: utils_disco.unpack_boxdim(x, hyp_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z, Y, X = 144, 144, 144\n",
    "Z2, Y2, X2 = int(Z/2), int(Y/2), int(X/2)\n",
    "Z4, Y4, X4 = int(Z/4), int(Y/4), int(X/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_T_cams = torch.from_numpy(data[\"pix_T_cams_raw\"][index:index+2]).reshape(hyp_B, hyp_S, 4, 4).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack((data[\"pix_T_cams_raw\"][index],data[\"pix_T_cams_raw\"][index+5])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camRs_T_origin = data['camR_T_origin_raw'][index:index+2]\n",
    "camRs_T_origin = torch.from_numpy(camRs_T_origin).reshape(hyp_B, hyp_S, 4, 4).cuda()\n",
    "camRs_T_origin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camRs_T_origin.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_camXs = data[\"rgb_camXs_raw\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_T_camRs = __u(utils_disco.safe_inverse(__p(camRs_T_origin)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_T_camXs = torch.from_numpy(data['origin_T_camXs_raw'][index:index+2])\n",
    "origin_T_camXs = origin_T_camXs.reshape(hyp_B, hyp_S, 4, 4).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camX0_T_camXs = utils_disco.get_camM_T_camXs(origin_T_camXs, ind=0)\n",
    "camRs_T_camXs = __u(torch.matmul(utils_disco.safe_inverse(__p(origin_T_camRs)), __p(origin_T_camXs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camXs_T_camRs = __u(utils_disco.safe_inverse(__p(camRs_T_camXs)))\n",
    "camX0_T_camRs = camXs_T_camRs[:,0]\n",
    "camX1_T_camRs = camXs_T_camRs[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camR_T_camX0  = utils_disco.safe_inverse(camX0_T_camRs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_path = data['tree_seq_filename'].replace(\"shamitl\",\"mprabhud\")\n",
    "tree_path = tree_path.replace(\"datasets\",\"dataset\")\n",
    "tree_file = pickle.load(open(os.path.join(tree_path),\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = hyp_N\n",
    "do_shape = True\n",
    "do_color = False\n",
    "do_material = False\n",
    "do_style = False\n",
    "do_style_content = False\n",
    "\n",
    "def trees_rearrange(trees):\n",
    "    updated_trees =[]\n",
    "    all_bboxes = []\n",
    "    all_scores = []\n",
    "    all_classes_list = []\n",
    "    for tree in trees:\n",
    "        tree,boxes,_,all_classes = bbox_rearrange(tree,boxes=[],classes={},all_classes=[])\n",
    "        if do_shape:\n",
    "            classes = [class_val[\"shape\"] for class_val  in all_classes]\n",
    "        elif do_color:\n",
    "            classes = [class_val[\"color\"] for class_val  in all_classes]\n",
    "        elif do_material:\n",
    "            classes = [class_val[\"material\"] for class_val  in all_classes]\n",
    "        elif do_style:\n",
    "            classes = [class_val[\"color\"]+\"_\"+ class_val[\"material\"] for class_val  in all_classes]\n",
    "        elif do_style_content:\n",
    "            classes = [class_val[\"shape\"]+\"/\"+class_val[\"color\"]+\"_\"+ class_val[\"material\"] for class_val  in all_classes]\n",
    "        elif do_color_content:            \n",
    "            classes = [class_val[\"shape\"]+\"/\"+class_val[\"color\"] for class_val  in all_classes]\n",
    "        elif do_material_content:            \n",
    "            classes = [class_val[\"shape\"]+\"/\"+ class_val[\"material\"] for class_val  in all_classes]\n",
    "        else:            \n",
    "            classes = [class_val[\"shape\"]+\"/\"+ class_val[\"color\"] +\"_\"+class_val[\"material\"] for class_val  in all_classes]\n",
    "        boxes = np.stack(boxes)\n",
    "        classes = np.stack(classes)\n",
    "        n,_  = boxes.shape \n",
    "        assert n == len(classes)\n",
    "        scores = np.pad(np.ones([n]),[0,N-n])\n",
    "        boxes = np.pad(boxes,[[0,N-n],[0,0]])\n",
    "        classes = np.pad(classes,[0,N-n])\n",
    "        updated_trees.append(tree)\n",
    "        all_classes_list.append(classes)\n",
    "        all_scores.append(scores)\n",
    "        all_bboxes.append(boxes)\n",
    "    all_bboxes = np.stack(all_bboxes)\n",
    "    all_scores = np.stack(all_scores)\n",
    "    all_classes_list = np.stack(all_classes_list)\n",
    "    return all_bboxes,all_scores,all_classes_list\n",
    "\n",
    "def bbox_rearrange(tree,boxes= [],classes={},all_classes=[]):\n",
    "    for i in range(0, tree.num_children):\n",
    "        updated_tree,boxes,classes,all_classes = bbox_rearrange(tree.children[i],boxes=boxes,classes=classes,all_classes=all_classes)\n",
    "        tree.children[i] = updated_tree     \n",
    "    if tree.function == \"describe\":\n",
    "        xmax,ymax,zmin,xmin,ymin,zmax = tree.bbox_origin\n",
    "        box = np.array([xmin,ymin,zmin,xmax,ymax,zmax])\n",
    "        tree.bbox_origin = box\n",
    "        boxes.append(box)\n",
    "        classes[\"shape\"] = tree.word\n",
    "        all_classes.append(classes)\n",
    "        classes = {}\n",
    "    if tree.function == \"combine\":\n",
    "        if \"large\" in tree.word or \"small\" in tree.word:\n",
    "            classes[\"size\"] = tree.word\n",
    "        elif \"metal\" in tree.word or \"rubber\" in tree.word:\n",
    "            classes[\"material\"] = tree.word\n",
    "        else:\n",
    "            classes[\"color\"] = tree.word\n",
    "    return tree,boxes,classes,all_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_boxesR,scores,classes = trees_rearrange([tree_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_boxesR = torch.from_numpy(gt_boxesR).cuda().float() # torch.Size([2, 3, 6])\n",
    "gt_boxesR_end = torch.reshape(gt_boxesR,[hyp_B,hyp_N,2,3])\n",
    "gt_boxesR_theta = utils_disco.get_alignedboxes2thetaformat(gt_boxesR_end)\n",
    "gt_boxesR_corners = utils_disco.transform_boxes_to_corners(gt_boxesR_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_boxesR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_boxesRMem_corners = __ub(utils_vox.Ref2Mem(__pb(gt_boxesR_corners),Z2,Y2,X2))\n",
    "gt_boxesRMem_end = utils_disco.get_ends_of_corner(gt_boxesRMem_corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_boxesRMem_theta = utils_disco.transform_corners_to_boxes(gt_boxesRMem_corners)\n",
    "gt_boxesRUnp_corners = __ub(utils_vox.Ref2Mem(__pb(gt_boxesR_corners),Z,Y,X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utils_disco' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cf14fa395c63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgt_boxesRUnp_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils_disco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ends_of_corner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_boxesRUnp_corners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'utils_disco' is not defined"
     ]
    }
   ],
   "source": [
    "gt_boxesRUnp_end = utils_disco.get_ends_of_corner(gt_boxesRUnp_corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_boxesX0_corners = __ub(utils_disco.apply_4x4(camX0_T_camRs, __pb(gt_boxesR_corners)))\n",
    "gt_boxesX1_corners = __ub(utils_disco.apply_4x4(camX1_T_camRs, __pb(gt_boxesR_corners)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_boxesX0_corners.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_T_cams.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_boxesXs_corners = __u(__ub(utils_disco.apply_4x4(__p(camXs_T_camRs), __p(__pb(gt_boxesR_corners).unsqueeze(1).repeat(1,hyp_S,1,1)) )))\n",
    "gt_boxesXs_end = __u(utils_disco.get_ends_of_corner(__p(gt_boxesXs_corners)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_boxesX0Mem_corners = __ub(utils_vox.Ref2Mem(__pb(gt_boxesX0_corners),Z2,Y2,X2))\n",
    "gt_boxesX0Mem_theta = utils_disco.transform_corners_to_boxes(gt_boxesX0Mem_corners)\n",
    "gt_boxesX0Mem_end = utils_disco.get_ends_of_corner(gt_boxesX0Mem_corners)\n",
    "gt_boxesX0_end = utils_disco.get_ends_of_corner(gt_boxesX0_corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_cornersX0_pix = __ub(utils_disco.apply_pix_T_cam(pix_T_cams[:,0], __pb(gt_boxesX0_corners)))\n",
    "gt_cornersX1_pix = __ub(utils_disco.apply_pix_T_cam(pix_T_cams[:,1], __pb(gt_boxesX1_corners)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_cornersX1_pix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_boxesXs_corners.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "__pbbs = lambda x: utils_disco.pack_boxbatchviewdim(x,hyp_B, hyp_N)\n",
    "__ubbs = lambda x: utils_disco.unpack_boxbatchviewdim(x,hyp_B, hyp_N)\n",
    "__pbbs_box = lambda x: utils_disco.pack_boxbatchviewdim_box(x,hyp_B, hyp_N)\n",
    "\n",
    "# gt_boxesXs_corners = __pbbs_box(gt_boxesXs_corners)\n",
    "# gt_cornersXs_pix = __ub(utils_disco.apply_pix_T_cam( __p(pix_T_cams),gt_boxesXs_corners ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def flip_image(img):\n",
    "\n",
    "    #read the image\n",
    "    im = Image.fromarray(img)\n",
    "\n",
    "    #flip image\n",
    "    out = im.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    return np.array(out)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_camXs = data[\"rgb_camXs_raw\"][:,:,:,:3]\n",
    "rgb_camX0 = torch.from_numpy(rgb_camXs[index]).permute(2,0,1).reshape(hyp_B, 3, 256, 256) #torch.from_numpy(np.fliplr(rgb_camXs[0,0])).reshape(1, 256, 256, 3).permute(0,3,1,2)\n",
    "rgb_camX1 = torch.from_numpy(rgb_camXs[index+1]).permute(2,0,1).reshape(hyp_B, 3, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import matplotlib\n",
    "from itertools import combinations\n",
    "\n",
    "def draw_corners_on_image(rgb, corners_cam, scores, tids, pix_T_cam,info_text=None):\n",
    "    # first we need to get rid of invalid gt boxes\n",
    "    # gt_boxes = trim_gt_boxes(gt_boxes)\n",
    "    B, C, H, W = list(rgb.shape)\n",
    "    assert(C==3)\n",
    "    B2, N, D, E = list(corners_cam.shape)\n",
    "    assert(B2==B)\n",
    "    assert(D==8) # 8 corners\n",
    "    assert(E==3) # 3D\n",
    "\n",
    "    #rgb = back2color(rgb)\n",
    "    corners_cam_ = torch.reshape(corners_cam, [B, N*8, 3])\n",
    "    corners_pix_ = utils_disco.apply_pix_T_cam(pix_T_cam, corners_cam_)\n",
    "    corners_pix = torch.reshape(corners_pix_, [B, N, 8, 2])\n",
    "    out = draw_boxes_on_image_py(rgb[0].cpu().numpy(),\n",
    "                                      corners_pix[0].cpu().numpy(),\n",
    "                                      scores[0].cpu().numpy(),\n",
    "                                      tids[0].cpu().numpy(),info_text)\n",
    "    out = torch.from_numpy(out).type(torch.ByteTensor).permute(2, 0, 1)\n",
    "    out = torch.unsqueeze(out, dim=0)\n",
    "    #out = preprocess_color(out)\n",
    "    out = torch.reshape(out, [1, C, H, W])\n",
    "    return out, corners_pix\n",
    "\n",
    "def draw_boxes_on_image_py(rgb, corners_pix, scores, tids,info_text=None, boxes=None, thickness=1,text=False):\n",
    "    # all inputs are numpy tensors\n",
    "    # rgb is H x W x 3\n",
    "    # corners_pix is N x 8 x 2, in xy order\n",
    "    # scores is N\n",
    "    # tids is N\n",
    "    # boxes is N x 9 < this is only here to print some rotation info\n",
    "    # pix_T_cam is 4 x 4\n",
    "    rgb = np.transpose(rgb, [1, 2, 0]) # put channels last\n",
    "    rgb = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    H, W, C = rgb.shape\n",
    "    assert(C==3)\n",
    "    N, D, E = corners_pix.shape\n",
    "    assert(D==8)\n",
    "    assert(E==2)\n",
    "\n",
    "    if boxes is not None:\n",
    "        rx = boxes[:,6]\n",
    "        ry = boxes[:,7]\n",
    "        rz = boxes[:,8]\n",
    "    else:\n",
    "        rx = 0\n",
    "        ry = 0\n",
    "        rz = 0\n",
    "\n",
    "    color_map = matplotlib.cm.get_cmap('tab20')\n",
    "    color_map = color_map.colors\n",
    "\n",
    "    # draw\n",
    "    for ind, corners in enumerate(corners_pix):\n",
    "        # corners is 8 x 2\n",
    "        # st()\n",
    "        if not np.isclose(scores[ind], 0.0):\n",
    "            # print 'score = %.2f' % scores[ind]\n",
    "            color_id = tids[ind] % 20\n",
    "            color = color_map[2]\n",
    "            color_text = color_map[2]\n",
    "\n",
    "            # st()\n",
    "\n",
    "            color = np.array(color)*255.0\n",
    "            # print 'tid = %d; score = %.3f' % (tids[ind], scores[ind])\n",
    "            if info_text is not None:\n",
    "                text_to_put = info_text[ind]\n",
    "                cv2.putText(rgb,\n",
    "                            text_to_put, \n",
    "                            (np.min(corners[:,0]), np.min(corners[:,1])),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.5, # font size\n",
    "                            color_text,\n",
    "                            2) # font weight\n",
    "\n",
    "            for c in corners:\n",
    "\n",
    "                # rgb[pt1[0], pt1[1], :] = 255\n",
    "                # rgb[pt2[0], pt2[1], :] = 255\n",
    "                # rgb[np.clip(int(c[0]), 0, W), int(c[1]), :] = 255\n",
    "\n",
    "                c0 = np.clip(int(c[0]), 0,  W-1)\n",
    "                c1 = np.clip(int(c[1]), 0,  H-1)\n",
    "                rgb[c1, c0, :] = 255\n",
    "\n",
    "            # we want to distinguish between in-plane edges and out-of-plane ones\n",
    "            # so let's recall how the corners are ordered:\n",
    "            xs = np.array([-1/2., -1/2., -1/2., -1/2., 1/2., 1/2., 1/2., 1/2.])\n",
    "            ys = np.array([-1/2., -1/2., 1/2., 1/2., -1/2., -1/2., 1/2., 1/2.])\n",
    "            zs = np.array([-1/2., 1/2., -1/2., 1/2., -1/2., 1/2., -1/2., 1/2.])\n",
    "            xs = np.reshape(xs, [8, 1])\n",
    "            ys = np.reshape(ys, [8, 1])\n",
    "            zs = np.reshape(zs, [8, 1])\n",
    "            offsets = np.concatenate([xs, ys, zs], axis=1)\n",
    "\n",
    "            corner_inds = list(range(8))\n",
    "            combos = list(combinations(corner_inds, 2))\n",
    "\n",
    "            for combo in combos:\n",
    "                pt1 = offsets[combo[0]]\n",
    "                pt2 = offsets[combo[1]]\n",
    "                # draw this if it is an in-plane edge\n",
    "                eqs = pt1==pt2\n",
    "                if np.sum(eqs)==2:\n",
    "                    i, j = combo\n",
    "                    pt1 = (corners[i, 0], corners[i, 1])\n",
    "                    pt2 = (corners[j, 0], corners[j, 1])\n",
    "                    retval, pt1, pt2 = cv2.clipLine((0, 0, W, H), pt1, pt2)\n",
    "                    if retval:\n",
    "                        cv2.line(rgb, pt1, pt2, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "                    # rgb[pt1[0], pt1[1], :] = 255\n",
    "                    # rgb[pt2[0], pt2[1], :] = 255\n",
    "    rgb = cv2.cvtColor(rgb.astype(np.uint8), cv2.COLOR_BGR2RGB)\n",
    "    # utils_basic.print_stats_py('rgb_uint8', rgb)\n",
    "    # imageio.imwrite('boxes_rgb.png', rgb)\n",
    "    return rgb\n",
    "\n",
    "def summ_box_by_corners(rgbR, corners, scores, tids, pix_T_cam, only_return=False):\n",
    "    # rgb is B x H x W x C\n",
    "    # corners is B x N x 8 x 3 \n",
    "    # scores is B x N\n",
    "    # tids is B x N\n",
    "    # pix_T_cam is B x 4 x 4\n",
    "    # st()\n",
    "    B, C, H, W = list(rgbR.shape)\n",
    "    boxes_vis = draw_corners_on_image(rgbR,corners,scores,tids,pix_T_cam,None)\n",
    "    return boxes_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tids = torch.from_numpy(np.reshape(np.arange(hyp_B*hyp_N),[hyp_B,hyp_N]))\n",
    "boxes_vis, corners_pix = summ_box_by_corners(rgb_camX0, gt_boxesX0_corners, torch.from_numpy(scores), tids, pix_T_cams[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(boxes_vis[0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tids = torch.from_numpy(np.reshape(np.arange(hyp_B*hyp_N),[hyp_B,hyp_N]))\n",
    "boxes_vis, corners_pix = summ_box_by_corners(rgb_camX1, gt_boxesX1_corners, torch.from_numpy(scores), tids, pix_T_cams[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(boxes_vis[0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corners_pix)\n",
    "print(corners_pix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_box(image, bboxes):\n",
    "    \n",
    "    num_obj= hyp_N #bboxes.size(0)\n",
    "    fig = plt.figure(figsize=(8,8*num_obj))\n",
    "    \n",
    "    axes = []\n",
    "    for o in range(num_obj):\n",
    "        ax = (fig.add_subplot(1,num_obj,o+1))\n",
    "        axes.append(ax)\n",
    "        box = bboxes[o]\n",
    "        x1,y1,x2,y2 = box1\n",
    "        x1 = int(x1.item()); x2 = int(x2.item()); y1 = int(y1.item()); y2 = int(y2.item())\n",
    "        ax.title.set_text(\"x1:{} , x2:{} , y1:{} , y2:{}\".format(x1,x2,y1,y2))\n",
    "        img = cv2.rectangle(image.copy(),(x1,y1),(x2,y2),(0,255,0),2)\n",
    "        plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(hyp_B):\n",
    "    box = [[torch.min(corners_pix[i, n, :, 0]), torch.min(corners_pix[i, n, :, 1]), torch.max(corners_pix[i, n, :, 0]), torch.max(corners_pix[i, n, :, 1])] for n in range(hyp_N)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    draw_bounding_box(rgb_camX1[0].permute(1,2,0).cpu().numpy(), box)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_box(image, sub_box, obj_box):\n",
    "\n",
    "    x1,y1,x2,y2 = sub_box\n",
    "    x1 = int(x1.item()); x2 = int(x2.item()); y1 = int(y1.item()); y2 = int(y2.item())\n",
    "    img = cv2.rectangle(image.copy(),(x1,y1),(x2,y2),(0,255,0),2)\n",
    "    \n",
    "    x1,y1,x2,y2 = obj_box\n",
    "    x1 = int(x1.item()); x2 = int(x2.item()); y1 = int(y1.item()); y2 = int(y2.item())\n",
    "    img = cv2.rectangle(img.copy(),(x1,y1),(x2,y2),(0,255,0),2)\n",
    "    \n",
    "    return img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disco",
   "language": "python",
   "name": "disco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
