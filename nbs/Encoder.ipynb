{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from core.model.scene_graph.scene_graph import SceneGraph\n",
    "from torchvision.models import resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.dataloader import CLEVR_train, collate_boxes\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised..... 234  files...\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CLEVR_train(root_dir='/home/mprabhud/dataset/clevr_lang/npys/ab_5t.txt')\n",
    "train_loader = DataLoader(train_dataset, batch_size=5, shuffle=True, collate_fn=collate_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in train_loader:\n",
    "    feed_dict_q, feed_dict_k, metadata = b\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict_q[\"images\"] = feed_dict_k[\"images\"].cuda()\n",
    "feed_dict_k[\"images\"] = feed_dict_k[\"images\"].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dim = 256):\n",
    "        super().__init__()\n",
    "        \n",
    "        \"\"\"\n",
    "        Input:\n",
    "            dim : final number of dimensions of the node and spatial embeddings\n",
    "        \n",
    "        Returns:\n",
    "            Intialises a model which has node embeddimgs and spatial embeddings\n",
    "        \"\"\"\n",
    "        \n",
    "        self.dim = dim\n",
    "        self.resnet = resnet34(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(self.resnet.children())[:-3])\n",
    "        \n",
    "        self.scene_graph = SceneGraph(feature_dim=self.dim, \n",
    "                                 output_dims=[self.dim,self.dim],\n",
    "                                 downsample_rate=16)\n",
    "        \n",
    "        self.node_viewpoint_transformation = nn.Sequential(nn.Linear(263,512),\n",
    "                                                nn.ReLU(),\n",
    "                                                nn.Linear(512,self.dim))\n",
    "\n",
    "        self.spatial_viewpoint_transformation = nn.Sequential(nn.Linear(263,512),\n",
    "                                                        nn.ReLU(),\n",
    "                                                        nn.Linear(512,self.dim))\n",
    "        \n",
    "    def merge_pose_with_scene_embeddings(self,\n",
    "                                     scene_embeddings,\n",
    "                                     view=None):\n",
    "        '''\n",
    "        Input\n",
    "            scene_embeddings: output of scene_graph module. A list of of tensors containing node and\n",
    "                              spatial embeddings of each batch element\n",
    "            view : a tensor of size [batch, 1, 7] containing information of relative egomotion\n",
    "                   between the two camera viewpoints\n",
    "            transform_node and transform spatial: boolean flags whether to do any transformation on nodes or not\n",
    "        Output\n",
    "            scene_embeddings: concatenated with pose vectors\n",
    "        '''\n",
    "\n",
    "        for batch_ind,(_, spatial_embeddings) in enumerate(scene_embeddings):\n",
    "            print(batch_ind)\n",
    "            num_obj_x = spatial_embeddings.shape[0]\n",
    "            num_obj_y = spatial_embeddings.shape[1]\n",
    "\n",
    "            print(\"Adding pose to spatial embeddings\")\n",
    "            # Broadcast view to spatial embedding dimension\n",
    "            view_spatial = view[batch_ind].unsqueeze(0).repeat(num_obj_x, num_obj_y, 1)\n",
    "            # Concatenate with visual embeddings\n",
    "            pose_with_features = torch.cat((view_spatial,spatial_embeddings), dim=2)\n",
    "            # Reassign the scene embeddings\n",
    "            scene_embeddings[batch_ind][1] = pose_with_features\n",
    "\n",
    "            ### To Do : Write some assertion test : (Saksham)\n",
    "\n",
    "        return scene_embeddings\n",
    "\n",
    "    def do_viewpoint_transformation(self,\n",
    "                                    scene_embeddings,\n",
    "                                    transform_node=True,\n",
    "                                    transform_spatial=False):\n",
    "\n",
    "        '''\n",
    "        Input:\n",
    "            scene_embeddings: output of scene_graph module concatenated with pose. A list of of tensors containing node and\n",
    "                              spatial embeddings of each batch element\n",
    "            transform_node and transform spatial: boolean flags whether to do any transformation on nodes or not\n",
    "        Output:\n",
    "            scene_embeddings: viewpoint transformed embeddings\n",
    "        '''\n",
    "        for ind,(_, spatial_embeddings) in enumerate(scene_embeddings):\n",
    "            # Do viewpoint transformation on spatial embeddings\n",
    "            print(\"viewpoint transform on spatial embeddings\")\n",
    "            scene_embeddings[ind][1] = self.spatial_viewpoint_transformation(scene_embeddings[ind][1])\n",
    "\n",
    "        return scene_embeddings\n",
    "\n",
    "    def forward(self,\n",
    "                feed_dict,\n",
    "                mode=\"node\",\n",
    "                rel_viewpoint=None):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            feed_dict: a dictionary containing list tensors containing images and bounding box data.\n",
    "            Each element of the feed_dict corresponds to one elment of the batch.\n",
    "            Inside each batch are contained [\"image\": Image tensor,\n",
    "                                             \"boxes\":Bounding box tensor,\n",
    "                                             bounding box\n",
    "                                            ]\n",
    "            mode: should be either 'node' or 'spatial' depending on what feature you want to extract\n",
    "        \"\"\"\n",
    "        num_batch = feed_dict[\"images\"].shape[0]\n",
    "        num_total_nodes = feed_dict[\"objects\"].sum().item()\n",
    "\n",
    "        image_features = self.feature_extractor(feed_dict[\"images\"])\n",
    "        outputs = self.scene_graph(image_features, feed_dict[\"objects_boxes\"], feed_dict[\"objects\"], mode=mode)\n",
    "\n",
    "        if mode==\"node\":\n",
    "            return outputs\n",
    "\n",
    "        if mode==\"spatial\" and rel_viewpoint is not None:\n",
    "            print(\"Ading viewpoint information to spatial features\")\n",
    "            outputs = self.merge_pose_with_scene_embeddings(outputs,rel_viewpoint)\n",
    "            outputs = self.do_viewpoint_transformation(outputs)\n",
    "            \n",
    "            return outputs\n",
    "            \n",
    "        if mode==\"spatial\" and rel_viewpoint is None:\n",
    "            return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enoder = encoder.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Mode** : Node Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict_ = feed_dict_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_outputs_ = encoder(feed_dict_, mode=\"node\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 7])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_viewpoint_ = metadata[\"rel_viewpoint\"]\n",
    "rel_viewpoint_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features_ = encoder.feature_extractor(feed_dict_[\"images\"])\n",
    "scene_graph_output = encoder.scene_graph(image_features_, feed_dict_[\"objects_boxes\"], feed_dict_[\"objects\"], mode=\"node\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_ind = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, torch.Size([2, 256]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scene_graph_output), scene_graph_output[batch_ind][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Mode** : Spatial Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ading viewpoint information to spatial features\n",
      "0\n",
      "Adding pose to spatial embeddings\n",
      "1\n",
      "Adding pose to spatial embeddings\n",
      "2\n",
      "Adding pose to spatial embeddings\n",
      "3\n",
      "Adding pose to spatial embeddings\n",
      "4\n",
      "Adding pose to spatial embeddings\n",
      "viewpoint transform on spatial embeddings\n",
      "viewpoint transform on spatial embeddings\n",
      "viewpoint transform on spatial embeddings\n",
      "viewpoint transform on spatial embeddings\n",
      "viewpoint transform on spatial embeddings\n"
     ]
    }
   ],
   "source": [
    "spatial_outputs_ = encoder(feed_dict_, mode=\"spatial\", rel_viewpoint= rel_viewpoint_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, torch.Size([2, 256]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spatial_outputs_), spatial_outputs_[batch_ind][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, torch.Size([2, 2, 256]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spatial_outputs_), spatial_outputs_[batch_ind][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching the Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict_k_ = feed_dict_k\n",
    "feed_dict_q_ = feed_dict_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_k_ = encoder(feed_dict_k_, mode=\"node\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_q_ = encoder(feed_dict_q_, mode=\"node\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_embeddings(output_k, output_q, mode = \"node\"):\n",
    "    \n",
    "    if mode==\"node\":\n",
    "        mode = 0\n",
    "    elif mode==\"spatial\":\n",
    "        mode = 1\n",
    "    else:\n",
    "        raise ValueError(\"Mode should be either node or spatial\")\n",
    "    \n",
    "    num_batch = len(output_k)\n",
    "    assert num_batch==len(output_q)   \n",
    "    \n",
    "    output_q_rearrange = []\n",
    "    \n",
    "    for batch_ind in range(num_batch):\n",
    "        \n",
    "        num_obj_in_batch = output_k[batch_ind][0].shape[0]\n",
    "        assert num_obj_in_batch==output_q[batch_ind][0].shape[0]\n",
    "        \n",
    "        if mode==\"spatial\":\n",
    "            assert num_obj_in_batch==output_q[batch_ind][1].shape[0]\n",
    "            assert num_obj_in_batch==output_q[batch_ind][1].shape[1]\n",
    "            assert output_k[batch_ind][1].shape[0]==output_k[batch_ind][1].shape[0]\n",
    "            assert output_k[batch_ind][1].shape[1]==output_k[batch_ind][1].shape[1]\n",
    "            assert output_k[batch_ind][1].shape[0]==output_k[batch_ind][1].shape[1]\n",
    "            assert output_k[batch_ind][1].shape[1]==output_k[batch_ind][1].shape[0]\n",
    "            \n",
    "        #flatten the node features only - \n",
    "        output_k[batch_ind][0] = output_k[batch_ind][0].view(-1,256)\n",
    "        output_q[batch_ind][0] = output_q[batch_ind][0].view(-1,256)\n",
    "        \n",
    "        \n",
    "        #form two pool from node features for nearest neighbour search\n",
    "        pool_e = output_k[batch_ind][0].clone().detach().cpu()\n",
    "        pool_g = output_q[batch_ind][0].clone().detach().cpu()\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            knn_e = NearestNeighbors(n_neighbors= num_obj_in_batch, metric=\"euclidean\")\n",
    "            knn_g = NearestNeighbors(n_neighbors= num_obj_in_batch, metric=\"euclidean\")\n",
    "\n",
    "            knn_g.fit(pool_g)\n",
    "            knn_e.fit(pool_e)\n",
    "            \n",
    "            paired = []\n",
    "            pairs = []\n",
    "            for index in range(num_obj_in_batch):  \n",
    "\n",
    "                #fit knn on each of the object \n",
    "                _, indices_e = knn_g.kneighbors(torch.reshape(pool_e[index], (1,-1)).detach().cpu())\n",
    "                indices_e = list(indices_e.flatten())\n",
    "                for e in indices_e:\n",
    "                    if e not in paired:\n",
    "                        paired.append(e)\n",
    "                        pairs.append(e)\n",
    "                        break\n",
    "        \n",
    "        print(pairs)\n",
    "        #rearranging the matched in output_q based on pair formed\n",
    "        \n",
    "    \n",
    "        #Rearranging the node_features in output_q based on pair formed\n",
    "        assert num_obj_in_batch == len(pairs)\n",
    "        \n",
    "        node_pool_rearranged = torch.zeros(pool_e.shape[0], 256)\n",
    "        for index_node in range(num_obj_in_batch):\n",
    "            pair_mapping_obj = pairs[index_node]\n",
    "            node_pool_rearranged[index_node] = output_q[batch_ind][0][pair_mapping_obj]\n",
    "        \n",
    "        output_q[batch_ind][0] = node_pool_rearranged.cuda()\n",
    "        \n",
    "        #If mode is spatial : also repair the spatial embeddings\n",
    "        if mode==\"spatial\":\n",
    "            spatial_pool_rearranged = torch.zeros(pool_e.shape[0], pool_e.shape[0], 256)\n",
    "            for index_subj in range(num_obj_in_batch):\n",
    "                for index_obj in range(num_obj_in_batch):\n",
    "                    pair_mapping_subj = pairs[index_subj]\n",
    "                    pair_mapping_obj = pairs[index_obj]\n",
    "                    spatial_pool_rearranged[index_subj][index_obj] = output_q[batch_ind][1][pair_mapping_subj][pair_mapping_obj]\n",
    "                    \n",
    "            output_q[batch_ind][1] = spatial_pool_rearranged\n",
    "        \n",
    "    return output_k, output_q    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0]\n",
      "[1, 0]\n",
      "[1, 0]\n",
      "[1, 0]\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "rearranged_output_k, rearranged_output_q = pair_embeddings(output_k_, output_q_, mode = \"node\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearranged_output_k==output_k_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearranged_output_q==output_q_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching the spatial embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_k__ = encoder(feed_dict_k_, mode=\"spatial\")\n",
    "output_q__ = encoder(feed_dict_q_, mode=\"spatial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_,__ = pair_embeddings(output_k_, output_q_, mode = \"spatial\")\n",
    "\n",
    "\n",
    "#Code breaking resolve later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0172,  0.0110, -0.0169,  ..., -0.0446,  0.1148, -0.0295],\n",
       "         [-0.0199,  0.0063, -0.0343,  ..., -0.0187,  0.1133, -0.0062]],\n",
       "\n",
       "        [[-0.0129,  0.0145,  0.0046,  ..., -0.0250,  0.1126, -0.0103],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan]]],\n",
       "       device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_k__[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten the embeddings across batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_features_across_batch(output_feature_list, mode=\"node\"):\n",
    "\n",
    "    num_batch = len(output_feature_list)\n",
    "    if mode==\"node\":  \n",
    "        node_features = output_feature_list[0][0].view(-1,256)\n",
    "\n",
    "        for num in range(1,num_batch):\n",
    "            node_features = torch.cat([node_features, output_feature_list[num][0]], dim =0)\n",
    "        \n",
    "        return node_features\n",
    "    \n",
    "    if mode==\"spatial\":\n",
    "        spatial_features = output_feature_list[0][1].view(-1,256)\n",
    "\n",
    "        for num in range(1, num_batch):\n",
    "            spatial_features = torch.cat([spatial_features, outputs[num][1].view(-1,256)], dim =0)\n",
    "            \n",
    "        return spatial_features\n",
    "    \n",
    "    raise ValueError(\"Training mode not defined properly. It should be either 'node' or 'spatial'.\" )       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_output_k = stack_features_across_batch(rearranged_output_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 256])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_output_k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True], device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_output_k[3] == rearranged_output_k[1][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 256])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_output_k[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([[-6.8771e-02, -5.9459e-02, -4.9381e-02, -4.5075e-02,  2.6175e-02,\n",
       "           -5.5583e-02, -2.8446e-02, -5.4258e-02, -1.2026e-01, -3.3940e-02,\n",
       "            7.4954e-02, -5.0520e-02,  7.1580e-02, -2.2378e-02, -1.0954e-01,\n",
       "            6.4361e-03, -3.7401e-02,  3.3686e-02, -7.0083e-03, -1.2406e-01,\n",
       "           -2.6524e-03,  1.3030e-02,  6.4491e-04,  8.5586e-03, -5.0108e-02,\n",
       "           -1.0728e-01,  8.1664e-02, -4.7497e-02,  5.5873e-04,  5.9002e-02,\n",
       "            7.8673e-02,  9.3005e-02,  2.6180e-02, -6.2063e-02,  4.2883e-02,\n",
       "           -7.0917e-03, -6.1418e-02, -8.3136e-02, -3.2738e-02, -9.6146e-02,\n",
       "           -8.8633e-02,  8.9317e-02, -7.7961e-02,  1.0480e-02, -1.8010e-01,\n",
       "           -1.2887e-01,  1.1231e-02, -2.2957e-02, -6.3313e-02,  2.9969e-02,\n",
       "            3.5156e-04,  2.4619e-02,  6.7547e-02,  3.9243e-04, -5.2683e-02,\n",
       "            1.1091e-01,  5.5613e-02,  9.2998e-02,  4.0873e-02,  1.7603e-01,\n",
       "           -1.4293e-02,  1.5070e-01,  1.4609e-01,  5.6070e-02,  2.2137e-04,\n",
       "            4.4992e-02, -9.4334e-02,  4.5181e-02,  8.6785e-02, -3.0784e-02,\n",
       "           -7.0660e-02,  5.2346e-02,  8.1571e-02, -8.0641e-03, -1.2590e-01,\n",
       "           -4.6442e-02, -1.7682e-02, -6.8666e-02,  1.3905e-02,  3.9417e-02,\n",
       "            1.6975e-01,  3.1725e-02,  9.9522e-02,  1.9461e-02, -4.2204e-02,\n",
       "           -7.2172e-03, -4.3168e-02, -3.1687e-02, -1.7335e-02,  2.4247e-02,\n",
       "           -7.7358e-04,  6.7146e-02,  4.0680e-02,  1.1776e-02, -8.5509e-02,\n",
       "            5.9734e-02, -7.8716e-02, -7.2214e-02, -1.8207e-02, -8.5092e-02,\n",
       "           -9.0689e-02,  3.5934e-02,  7.4821e-02,  1.6530e-02, -1.2425e-02,\n",
       "            8.9658e-02, -2.1772e-02, -1.1185e-01,  7.9333e-02, -2.5772e-02,\n",
       "           -3.4494e-02, -1.1145e-01,  1.2298e-02,  7.2377e-02,  7.8370e-02,\n",
       "           -3.1458e-02, -2.0222e-02,  5.9214e-02,  6.5392e-02, -8.7716e-02,\n",
       "           -6.2477e-02, -6.0512e-03, -4.3805e-02, -5.4735e-02, -9.0340e-02,\n",
       "           -4.7468e-02,  7.8445e-02,  5.8485e-02, -4.4170e-02,  4.6353e-02,\n",
       "            9.8659e-02, -4.0431e-02, -4.4735e-02, -2.5693e-02, -4.3626e-04,\n",
       "            5.1200e-02, -7.3843e-02, -2.6005e-02,  3.8470e-02, -2.5553e-02,\n",
       "            6.0818e-02, -9.8471e-02, -2.7008e-02,  1.5472e-02,  8.9574e-02,\n",
       "           -1.3272e-03,  1.2979e-01,  1.6798e-02, -6.8542e-04,  7.4052e-02,\n",
       "            9.6646e-02,  9.9408e-02,  3.6643e-02,  5.8066e-02, -4.5043e-02,\n",
       "            9.1068e-02, -6.0346e-02, -1.2241e-02, -4.0356e-02, -5.2657e-02,\n",
       "            2.9875e-02,  2.4543e-02, -1.0067e-01, -1.2849e-01,  1.2262e-02,\n",
       "           -9.1563e-02,  5.3856e-02, -5.7119e-02, -2.3013e-02, -1.0149e-01,\n",
       "            1.3164e-02,  5.1968e-02,  8.9973e-02, -6.6554e-02,  5.2957e-02,\n",
       "           -2.7641e-02, -8.8247e-02, -3.6883e-02, -3.1680e-02, -2.9521e-02,\n",
       "            7.4435e-02,  6.0648e-02,  2.6451e-02, -4.1661e-02,  8.4718e-02,\n",
       "           -9.5204e-03, -1.0096e-03,  4.7448e-02, -4.8490e-02, -2.1002e-02,\n",
       "            6.9736e-02, -1.5501e-02, -7.6676e-02, -2.8688e-02,  2.4277e-02,\n",
       "           -1.3509e-02, -4.8996e-02,  4.6876e-03, -5.1035e-02, -2.3833e-02,\n",
       "           -1.8403e-02,  5.1482e-02, -8.3618e-02,  6.2243e-02, -7.7395e-03,\n",
       "           -1.2965e-01, -3.0650e-02,  4.3978e-02, -9.8329e-02, -1.3262e-03,\n",
       "            1.8848e-02,  3.8429e-03,  3.3773e-02, -3.9740e-02,  5.7771e-02,\n",
       "            1.9039e-02,  5.6812e-02, -1.4340e-02, -9.1403e-02, -1.1866e-02,\n",
       "           -1.1348e-01,  1.4218e-02,  1.6016e-03, -5.8438e-02, -1.4054e-01,\n",
       "           -1.1100e-02,  4.4328e-02,  4.1587e-03,  7.2351e-02, -4.6628e-02,\n",
       "            7.9784e-04,  1.0963e-04,  3.3928e-02, -6.3218e-03,  3.0533e-03,\n",
       "            6.1888e-02,  3.1430e-02,  4.0383e-03, -8.2622e-02,  1.7371e-02,\n",
       "           -1.5587e-04,  3.4318e-02, -7.7583e-02, -5.7653e-02, -1.3324e-02,\n",
       "           -6.7218e-02, -1.1400e-01, -5.6860e-03, -6.1335e-02, -1.2646e-02,\n",
       "           -2.5426e-02,  1.9338e-02, -7.5477e-02, -4.8719e-02,  2.3729e-02,\n",
       "            2.8031e-02],\n",
       "          [-7.3078e-02, -9.6412e-03, -1.8672e-02, -1.9985e-02,  3.4912e-02,\n",
       "            2.0023e-02, -8.6598e-03, -6.2555e-02, -1.0783e-01,  1.2717e-02,\n",
       "            2.5883e-02, -5.0711e-02,  7.6763e-02, -7.4767e-02, -6.7710e-02,\n",
       "           -2.8037e-02, -4.5538e-02,  5.3152e-02, -2.7802e-02, -8.4173e-02,\n",
       "            1.9629e-02,  4.5367e-03, -2.0181e-02, -1.5238e-02, -2.7354e-02,\n",
       "           -1.5126e-01,  7.7554e-02, -1.9981e-02,  6.7031e-03,  5.7467e-02,\n",
       "            1.2825e-01,  7.6726e-02, -7.1479e-04, -1.0498e-01,  4.9648e-02,\n",
       "           -1.1581e-02, -9.0919e-02, -6.3412e-02, -5.5413e-02, -6.1974e-02,\n",
       "           -1.2952e-01,  8.4004e-02, -4.5887e-02,  4.6037e-02, -1.7905e-01,\n",
       "           -1.2119e-01,  7.3558e-03, -2.4180e-02, -4.6464e-02,  5.0410e-02,\n",
       "            3.1733e-02, -3.2461e-02,  4.9432e-02, -2.8708e-03, -7.3183e-02,\n",
       "            5.9220e-02,  7.5473e-02,  1.0317e-01,  6.9497e-02,  1.7870e-01,\n",
       "            2.5871e-02,  1.7990e-01,  1.2985e-01,  1.4528e-02,  2.3995e-03,\n",
       "            4.3362e-02, -5.7441e-02,  1.2805e-02,  9.8304e-02, -5.9246e-03,\n",
       "           -1.0973e-01,  3.2144e-02,  6.7301e-02, -3.9965e-02, -9.9214e-02,\n",
       "           -1.8144e-02,  4.4348e-03, -6.6961e-02,  2.8054e-04,  5.6868e-02,\n",
       "            1.5781e-01,  2.3931e-02,  1.1344e-01,  6.8199e-02, -6.7811e-02,\n",
       "            9.9136e-02, -2.5734e-02, -2.8988e-02, -1.2285e-02,  6.1259e-02,\n",
       "           -2.7359e-02,  5.6958e-02,  8.0170e-03,  1.1950e-02, -1.2304e-01,\n",
       "            1.0628e-01, -7.6496e-02, -8.5114e-02, -5.5059e-03, -8.9116e-02,\n",
       "           -6.7236e-02,  6.3900e-02,  5.5239e-02,  6.0311e-02, -5.2497e-02,\n",
       "            9.4935e-02, -1.2095e-02, -9.6583e-02,  1.0585e-01, -3.8027e-02,\n",
       "           -1.1442e-02, -6.5038e-02,  4.8104e-02,  5.0276e-02,  8.0971e-02,\n",
       "           -4.3578e-02, -2.4125e-02,  3.4796e-02,  8.6444e-02, -4.7560e-02,\n",
       "           -1.0561e-02,  2.0934e-03, -5.0509e-02, -6.1932e-02, -9.1288e-02,\n",
       "           -3.7063e-02,  1.0163e-01,  1.1327e-02, -6.5722e-03,  4.0726e-02,\n",
       "            7.7416e-02, -6.2790e-02, -1.9563e-02, -6.7240e-02,  2.4025e-02,\n",
       "            1.5273e-02, -6.6650e-02, -5.9805e-03,  7.6777e-02, -1.6471e-02,\n",
       "            5.9822e-02, -4.4783e-02, -1.3889e-02,  1.8429e-02,  6.5805e-02,\n",
       "            2.1736e-02,  1.0094e-01,  1.5172e-02,  4.7625e-03,  9.1463e-02,\n",
       "            1.0666e-01,  5.7399e-02,  6.9632e-03,  6.3073e-02, -6.6831e-02,\n",
       "            9.9548e-02, -8.7680e-02, -2.1706e-02, -8.8503e-02, -4.6071e-02,\n",
       "            1.4860e-02, -4.5971e-03, -7.4559e-02, -1.0798e-01,  2.3157e-02,\n",
       "           -7.8183e-02,  8.6222e-02, -3.8777e-02, -1.2991e-02, -1.1860e-01,\n",
       "            2.2485e-02,  4.6708e-02,  1.0427e-01, -3.8273e-02,  2.8459e-02,\n",
       "            1.1664e-02, -8.1576e-02, -3.8908e-02, -1.3500e-02, -5.3583e-02,\n",
       "            9.0874e-02,  7.0501e-02,  2.3860e-02, -5.4870e-02,  4.4030e-02,\n",
       "           -2.3731e-02,  2.0184e-02,  4.6935e-02, -9.8153e-02, -3.9797e-02,\n",
       "            8.0341e-02, -2.5056e-03, -4.9901e-02, -1.0603e-02,  3.5009e-02,\n",
       "            2.7698e-02, -1.7290e-02,  1.5054e-02, -4.0727e-02, -6.5459e-02,\n",
       "           -3.2270e-02,  4.3556e-02, -3.5457e-02,  7.6190e-02,  1.0853e-03,\n",
       "           -1.2695e-01, -3.7386e-02,  6.4167e-02, -8.2060e-02, -3.1588e-04,\n",
       "            1.0568e-02,  9.5128e-03,  2.5606e-02, -3.5423e-02,  5.0876e-02,\n",
       "           -1.9520e-02,  3.8617e-02,  2.7754e-02, -1.0763e-01, -6.9646e-04,\n",
       "           -9.8354e-02,  2.3649e-02, -1.2653e-03, -3.2122e-02, -1.3085e-01,\n",
       "           -3.5205e-02,  1.1645e-02,  2.9515e-02,  5.2021e-02, -3.2215e-02,\n",
       "           -3.3511e-02,  2.1516e-03,  1.7162e-02,  7.8509e-03, -9.6273e-03,\n",
       "            7.8586e-02,  2.3749e-02, -2.1829e-02, -5.7017e-02,  3.0723e-02,\n",
       "            2.8034e-04,  4.0171e-02, -5.2593e-02, -7.1592e-02, -4.0955e-03,\n",
       "           -6.0609e-02, -6.9725e-02,  2.1014e-02, -5.7519e-02, -9.2103e-03,\n",
       "            6.3237e-02,  2.7600e-02, -9.5160e-02, -9.2636e-02, -3.7453e-03,\n",
       "            5.0184e-02]], device='cuda:0', grad_fn=<ViewBackward>), None],\n",
       " [tensor([[-1.0753e-01,  2.2739e-02, -8.0088e-02, -1.3966e-01, -1.8675e-03,\n",
       "           -2.4762e-02,  3.5747e-02,  5.5452e-02, -6.2346e-02,  3.4049e-02,\n",
       "            9.6816e-04, -6.2206e-02,  1.0048e-01, -5.6207e-03,  3.9660e-02,\n",
       "           -1.2758e-03,  6.8652e-03,  2.2089e-02, -5.2536e-04, -6.0241e-02,\n",
       "            8.3545e-02,  1.1123e-02, -1.3460e-02,  2.4579e-02, -4.6091e-03,\n",
       "           -1.0944e-01,  1.0634e-01, -9.6206e-02,  3.9695e-02,  1.9964e-02,\n",
       "           -1.2948e-02,  1.8993e-02, -9.2177e-03, -1.0873e-01, -4.0966e-02,\n",
       "           -7.3712e-02, -8.3967e-02,  1.6691e-02, -1.7779e-02, -7.4580e-02,\n",
       "           -6.2648e-02,  7.6659e-03,  3.8074e-02,  2.5643e-03, -1.1193e-01,\n",
       "            5.9089e-02, -2.0983e-02, -6.0469e-02, -1.0093e-01,  7.3638e-02,\n",
       "            3.9125e-02, -9.1624e-02,  1.2975e-02,  8.8582e-03, -5.3785e-02,\n",
       "            8.8534e-02,  2.9060e-03,  7.7231e-02,  3.8025e-02,  4.2877e-02,\n",
       "           -9.7933e-03,  1.6805e-01,  6.2228e-02,  1.0313e-02,  8.9909e-03,\n",
       "           -7.6339e-03,  5.6434e-02, -2.3481e-02,  3.8791e-02, -9.2935e-02,\n",
       "           -1.3586e-01,  4.6667e-02,  1.1538e-01, -4.5462e-02, -1.1167e-02,\n",
       "           -7.5074e-02,  7.0943e-03, -3.6107e-02, -2.2280e-02,  7.6001e-02,\n",
       "            1.5931e-01,  6.4116e-02, -3.7771e-02,  9.8370e-03, -6.4333e-02,\n",
       "            1.0464e-01,  1.0103e-02, -7.6501e-02, -1.4938e-01, -6.9719e-02,\n",
       "           -3.0031e-04,  5.4808e-03, -8.6708e-02, -9.3650e-05, -4.3042e-02,\n",
       "           -6.2255e-02, -4.9672e-02, -5.4709e-02,  3.3570e-02, -6.1215e-02,\n",
       "            1.9492e-02, -1.6957e-02,  9.5001e-02,  7.5666e-02, -5.2155e-02,\n",
       "            7.1556e-02,  2.1225e-02, -3.2033e-02, -2.5969e-02, -7.7055e-02,\n",
       "           -1.5725e-02, -1.1987e-01,  5.1109e-02, -1.1477e-02,  9.6000e-02,\n",
       "           -2.4887e-02,  6.2616e-02, -5.4357e-02,  9.4823e-02, -6.3325e-02,\n",
       "           -4.7234e-02,  6.3858e-03, -7.4733e-02, -2.3079e-03, -4.7177e-02,\n",
       "            1.0849e-02,  7.1226e-02, -2.8927e-03, -2.8925e-02,  3.0868e-02,\n",
       "            3.1052e-02, -8.3045e-02, -7.3097e-02, -9.0348e-02, -2.6022e-02,\n",
       "            6.9715e-02, -8.3704e-03, -4.5642e-02, -2.3120e-02, -1.1919e-01,\n",
       "            4.7353e-02, -2.2133e-02,  2.3279e-02,  8.5909e-02, -5.1582e-02,\n",
       "           -2.1649e-03,  6.1945e-02, -2.0026e-02,  1.6676e-02,  8.4199e-02,\n",
       "            1.2574e-01,  8.8542e-02,  1.2676e-03,  6.9871e-02, -3.9576e-02,\n",
       "            9.8287e-02, -6.7193e-03, -6.4496e-03, -1.3095e-01,  3.5870e-02,\n",
       "            8.5318e-02, -2.7655e-02, -1.2040e-01, -7.2197e-02,  5.3277e-02,\n",
       "           -7.5431e-02,  2.4940e-02,  5.2411e-02, -9.9562e-03, -4.7885e-02,\n",
       "            1.5120e-02,  1.5115e-01,  8.5454e-02,  2.2446e-02,  1.4501e-01,\n",
       "            2.2152e-02, -5.6091e-02, -4.0046e-02, -1.0578e-01, -3.4582e-02,\n",
       "            3.9355e-02,  2.4424e-03,  6.9309e-02,  2.2194e-02,  3.2993e-02,\n",
       "            4.3227e-02, -9.2040e-03,  6.5186e-02, -1.6200e-01, -2.8268e-02,\n",
       "            1.1585e-01, -2.5882e-02, -3.9208e-02,  3.6886e-02, -3.8386e-02,\n",
       "            1.8682e-02, -6.2864e-03,  6.0230e-02, -7.8371e-02, -3.2932e-02,\n",
       "           -5.7596e-02, -1.6822e-03, -5.4311e-02,  2.8956e-02, -1.9364e-02,\n",
       "           -5.2406e-02, -6.5092e-02, -3.8508e-02, -1.3526e-01, -1.4766e-02,\n",
       "            5.5538e-02,  5.1588e-02,  2.1993e-02, -9.9477e-02,  2.4627e-02,\n",
       "            1.6571e-02,  8.3223e-02,  7.6244e-02, -8.6780e-02, -6.8754e-02,\n",
       "           -1.0827e-01,  3.7966e-02,  1.5513e-01, -1.8489e-02, -5.1810e-02,\n",
       "            6.7707e-02, -1.1698e-02,  5.2848e-02,  1.9128e-02, -4.4601e-02,\n",
       "            7.2700e-03, -3.7861e-02,  1.4791e-02,  1.7048e-02,  2.5247e-02,\n",
       "            5.6638e-02, -9.0885e-06, -1.1852e-02, -1.0868e-01,  9.1554e-02,\n",
       "           -5.1552e-02,  6.3423e-03, -2.5882e-02, -5.5848e-03, -1.0382e-02,\n",
       "           -6.0795e-03, -5.4547e-02, -6.3255e-02, -2.8859e-03, -8.2918e-02,\n",
       "           -6.3080e-02,  3.0593e-02, -8.3568e-02, -1.8631e-03,  5.9775e-03,\n",
       "            9.2397e-03],\n",
       "          [-1.0706e-01,  1.5605e-02, -3.9961e-02, -1.3232e-01,  1.5662e-02,\n",
       "            1.3135e-03, -1.9082e-02,  2.0125e-02, -5.8060e-02,  2.8144e-02,\n",
       "           -3.7551e-02, -9.2708e-02,  1.0629e-01,  4.6516e-03,  1.9640e-02,\n",
       "           -5.3159e-02, -2.9056e-02,  3.0738e-03,  2.4841e-02, -6.1013e-02,\n",
       "            7.7084e-02,  1.3753e-02, -2.2786e-02,  5.2651e-02, -3.3805e-02,\n",
       "           -1.2703e-01,  1.2184e-01, -9.0203e-02,  2.8722e-02,  3.8597e-02,\n",
       "           -7.1795e-03, -1.0451e-02, -7.4291e-03, -9.7327e-02, -5.8703e-02,\n",
       "           -6.5177e-02, -5.8073e-02,  1.9333e-02, -2.0450e-02, -8.1832e-02,\n",
       "           -2.8682e-02, -1.1038e-02,  5.0203e-02,  1.6806e-02, -9.2460e-02,\n",
       "            7.1697e-02, -3.0320e-03, -7.5061e-02, -5.8327e-02,  7.8227e-02,\n",
       "            1.3648e-02, -7.4119e-02,  7.1366e-03,  1.6496e-02, -6.1644e-02,\n",
       "            7.8470e-02, -2.1498e-02,  4.4623e-02,  1.0083e-02,  4.0381e-02,\n",
       "            1.5523e-02,  2.0664e-01,  9.0663e-02,  3.8025e-02,  1.2698e-02,\n",
       "           -1.1587e-02,  7.3179e-02,  1.9979e-02,  4.6203e-02, -3.2523e-02,\n",
       "           -1.3198e-01,  2.2618e-02,  1.2803e-01, -8.5695e-02,  2.8027e-03,\n",
       "           -6.9383e-02,  2.5115e-02, -3.4354e-02, -3.4383e-02,  5.9864e-02,\n",
       "            1.3575e-01,  5.1573e-02, -5.7967e-02,  2.0240e-02, -1.0219e-01,\n",
       "            1.1762e-01,  2.3007e-02, -1.0169e-01, -1.3841e-01, -7.6807e-02,\n",
       "           -1.0226e-02,  3.7648e-02, -1.0540e-01, -6.1489e-04, -6.0888e-02,\n",
       "           -6.2624e-02, -3.4205e-02, -5.7648e-02,  2.6390e-02, -3.9990e-02,\n",
       "            3.4047e-02,  2.6507e-03,  2.7008e-02,  5.6883e-02, -5.4473e-02,\n",
       "            1.2466e-01,  3.6856e-02, -2.8464e-02, -1.8494e-02, -5.4082e-02,\n",
       "           -1.3817e-02, -1.1377e-01,  9.6997e-02, -1.1837e-03,  9.7437e-02,\n",
       "           -3.4170e-02,  8.5666e-02, -4.4531e-02,  9.3850e-02, -3.6651e-02,\n",
       "           -3.7179e-02,  4.0858e-02, -5.7078e-02,  2.9423e-03, -4.3464e-02,\n",
       "           -2.7983e-02,  7.8595e-02, -1.3881e-02, -1.7764e-03,  1.3792e-02,\n",
       "            4.5936e-02, -5.4893e-02, -6.5985e-02, -8.8886e-02, -7.3538e-04,\n",
       "            6.3150e-02, -5.1973e-03, -3.2898e-02, -1.7688e-02, -9.7251e-02,\n",
       "            4.5304e-02, -8.5659e-03,  6.2313e-02,  8.7438e-02, -5.2161e-02,\n",
       "           -1.6004e-02,  5.4161e-02, -2.3418e-02,  4.3320e-02,  7.8593e-02,\n",
       "            9.5906e-02,  6.2888e-02,  1.1087e-02,  1.9227e-02, -5.6659e-02,\n",
       "            5.4272e-02, -5.0663e-02, -3.7114e-02, -1.0025e-01,  2.3282e-02,\n",
       "            8.7647e-02, -5.8209e-02, -1.2985e-01, -9.7207e-02,  5.3310e-02,\n",
       "           -9.6270e-02,  1.6659e-02,  7.1970e-02, -2.4178e-02, -4.1501e-02,\n",
       "           -1.2988e-02,  1.6124e-01,  7.1295e-02,  3.1307e-02,  1.4766e-01,\n",
       "            1.4556e-02, -5.1558e-02, -2.2677e-02, -4.6830e-02,  8.3899e-03,\n",
       "            6.3620e-02,  1.4213e-03,  5.2178e-02,  4.6112e-02,  5.6465e-02,\n",
       "            2.3756e-02,  3.2607e-02,  2.2011e-02, -1.6463e-01, -4.5233e-02,\n",
       "            5.3075e-02, -5.1173e-02, -6.9766e-02,  3.5685e-02, -2.1564e-02,\n",
       "            3.0213e-02, -2.3547e-04,  2.0140e-02, -8.1690e-02, -5.8160e-02,\n",
       "           -1.0721e-01, -6.3481e-03, -4.6369e-02,  4.0446e-02, -4.6842e-02,\n",
       "           -6.6601e-02, -6.4999e-02, -4.0018e-02, -1.1714e-01,  8.0502e-03,\n",
       "            8.2207e-02,  5.7855e-02,  7.5117e-02, -1.1302e-01, -1.0864e-03,\n",
       "           -7.2948e-03,  8.2081e-02,  6.4429e-02, -2.6021e-02, -3.6089e-02,\n",
       "           -1.2004e-01,  5.4429e-02,  1.4888e-01, -2.0297e-02, -3.0804e-02,\n",
       "            9.2277e-02, -1.0836e-02,  2.1580e-02,  3.8992e-03, -6.6553e-02,\n",
       "            1.8240e-02, -7.6668e-02,  9.8221e-03,  2.8388e-02,  3.0534e-02,\n",
       "            3.8813e-02,  2.4209e-03, -2.1277e-02, -6.9048e-02,  1.2656e-01,\n",
       "           -1.8896e-02,  3.1770e-03, -6.0236e-02,  9.9674e-03, -2.0006e-02,\n",
       "            1.3034e-02, -6.6848e-02, -6.8661e-02,  1.6932e-02, -9.3856e-02,\n",
       "           -5.5174e-02,  8.9547e-03, -6.2534e-02,  7.4701e-03,  1.3916e-02,\n",
       "            5.9233e-03]], device='cuda:0', grad_fn=<ViewBackward>), None],\n",
       " [tensor([[-1.2227e-02,  5.5506e-02, -1.8612e-01, -1.3513e-01, -2.1894e-02,\n",
       "           -3.0590e-02, -9.7133e-02, -3.6018e-02,  4.3599e-02, -3.5564e-03,\n",
       "            5.4564e-03, -8.6492e-02,  5.7112e-02, -1.8285e-02, -1.5881e-02,\n",
       "           -8.5626e-02, -2.9794e-02, -5.8126e-03,  3.7647e-02, -1.0139e-01,\n",
       "            7.1894e-03,  4.9149e-02, -1.3568e-02, -5.8122e-03,  3.8862e-02,\n",
       "           -6.8259e-02,  7.4590e-02, -1.6572e-02,  9.3973e-02,  6.0899e-02,\n",
       "            6.6959e-02, -1.6414e-02, -1.4905e-01, -8.4843e-02, -5.3082e-02,\n",
       "           -7.4977e-02, -7.1483e-02,  3.3413e-03, -1.0139e-02, -5.2369e-02,\n",
       "            1.3992e-02, -3.6542e-02,  1.4818e-02, -5.2729e-02, -5.9237e-02,\n",
       "            8.2152e-02,  2.7311e-02, -6.5109e-02, -7.0203e-02,  9.6719e-02,\n",
       "           -1.5992e-02, -5.3758e-02,  4.3614e-02, -9.0535e-03, -7.1715e-02,\n",
       "           -1.9657e-02,  3.1422e-02,  3.9766e-02, -5.2566e-02,  7.3664e-02,\n",
       "            3.1280e-02,  1.3042e-01,  9.9403e-02, -6.1941e-02, -4.4050e-02,\n",
       "            6.5574e-02, -4.0954e-02,  2.3074e-02,  4.1995e-02, -7.7565e-02,\n",
       "           -1.4719e-01,  4.8321e-02,  5.7491e-02, -7.0849e-02,  2.2997e-02,\n",
       "           -6.1274e-02, -1.3798e-02,  1.8910e-02, -2.6121e-02, -4.6429e-03,\n",
       "            9.7287e-02,  4.9460e-02, -7.3593e-02,  9.0913e-02, -4.2058e-02,\n",
       "            5.5668e-02,  5.9192e-02, -1.2729e-01, -9.5475e-02, -1.0784e-01,\n",
       "            7.9086e-03,  1.1245e-01, -1.0240e-01,  3.3246e-02,  1.8964e-02,\n",
       "            1.0070e-01, -4.0802e-02, -5.2913e-02, -4.0248e-02, -4.9641e-02,\n",
       "           -3.1518e-02,  8.6838e-02,  4.8213e-02,  2.5849e-02, -7.7989e-02,\n",
       "            1.3683e-01,  1.1316e-01, -6.2432e-02,  5.1969e-02, -1.1144e-01,\n",
       "           -2.1318e-02, -7.0068e-02, -2.2306e-02, -3.2583e-02,  7.2213e-02,\n",
       "           -2.9121e-02,  1.0010e-01, -3.6477e-02,  6.5295e-02, -2.4584e-02,\n",
       "            4.9005e-02, -1.6846e-02,  7.3521e-03,  3.6854e-02,  1.4361e-02,\n",
       "           -3.3726e-02,  1.2421e-01, -1.3346e-04,  8.3002e-03, -3.4658e-02,\n",
       "            3.0936e-02, -7.3886e-02, -1.3196e-02, -7.8271e-02,  4.2292e-02,\n",
       "            2.0116e-02, -4.6686e-02, -4.8805e-02, -2.2857e-02,  6.6888e-04,\n",
       "            3.1985e-02, -2.6790e-02,  6.5685e-03,  8.9170e-02, -3.8164e-03,\n",
       "           -3.5240e-02,  7.8341e-02,  1.1080e-02,  1.0889e-01,  1.1146e-01,\n",
       "            1.1770e-01, -5.0002e-03, -7.2468e-02,  1.6276e-03, -6.8698e-02,\n",
       "            2.5166e-02, -6.0122e-02, -1.5074e-02, -9.9232e-02, -6.8348e-02,\n",
       "            8.5329e-02,  7.6549e-03, -1.2183e-01, -5.0983e-02,  6.4132e-02,\n",
       "           -9.0384e-02,  4.9018e-02,  5.4699e-02, -5.9810e-02, -2.3249e-02,\n",
       "           -3.4868e-02,  9.6209e-02,  5.9269e-03, -7.8567e-03,  6.4146e-02,\n",
       "            2.7421e-02,  6.6444e-03, -1.3250e-02, -2.0190e-02, -6.5269e-02,\n",
       "            8.4172e-03, -6.7464e-02,  1.6842e-04, -7.1558e-02,  4.2192e-02,\n",
       "           -2.8428e-02,  4.8016e-03,  1.2341e-01, -9.7648e-02, -4.4098e-02,\n",
       "            4.8838e-02, -6.3473e-03, -3.1140e-02, -1.8917e-02,  9.7223e-03,\n",
       "            3.4895e-04,  4.1463e-02,  1.2876e-02, -1.0252e-01,  1.3472e-02,\n",
       "           -5.7881e-02, -2.0633e-02, -1.4003e-02,  8.1160e-02, -4.9943e-03,\n",
       "           -1.1407e-01, -5.8203e-02, -3.6314e-02, -5.2281e-02, -4.3336e-02,\n",
       "            1.2671e-01,  5.6050e-03, -2.9995e-02, -6.3722e-02,  1.7511e-02,\n",
       "           -2.6890e-02,  1.1035e-01,  2.5831e-02, -1.0247e-02,  6.9489e-03,\n",
       "           -1.8024e-01, -1.5984e-03,  2.0776e-01,  1.5408e-02, -5.3173e-02,\n",
       "            3.8205e-02,  4.3768e-03,  1.7257e-02, -1.7904e-02, -1.5351e-02,\n",
       "           -4.9914e-02,  6.9398e-03, -1.0828e-02,  5.7155e-02, -3.6704e-02,\n",
       "           -2.3490e-02, -7.9962e-03, -4.4357e-02, -5.0953e-02,  1.2780e-01,\n",
       "            1.1081e-02,  2.5057e-02, -3.6376e-02, -3.4678e-02, -3.0874e-02,\n",
       "           -7.4014e-02, -1.0536e-01, -1.6583e-03,  2.8324e-02, -1.6391e-02,\n",
       "           -4.9303e-02,  4.1555e-02, -3.9901e-02, -7.2784e-02,  8.0484e-02,\n",
       "            4.1026e-02],\n",
       "          [-4.6627e-02,  2.4045e-02, -1.4781e-01, -5.6096e-02, -2.6545e-02,\n",
       "           -4.1258e-02, -2.9518e-02,  1.4239e-02,  1.2693e-02,  2.6283e-02,\n",
       "           -1.2382e-02, -2.7822e-02,  7.0612e-02, -1.3689e-02, -3.5220e-02,\n",
       "           -3.5770e-02,  1.7479e-02,  4.8419e-02,  3.2351e-02, -1.0240e-01,\n",
       "            4.2313e-02,  4.6434e-02,  2.6326e-02, -2.1447e-02, -2.1750e-02,\n",
       "           -9.4128e-02,  1.7171e-01,  9.3736e-03,  2.0146e-02,  6.8373e-02,\n",
       "            8.3705e-02, -1.8995e-03, -9.6220e-02, -8.9872e-02, -4.2083e-02,\n",
       "           -1.0121e-01, -1.0374e-01, -2.6527e-02,  3.7179e-02, -9.9856e-02,\n",
       "           -3.2807e-02, -4.3586e-02,  1.6051e-02, -6.2921e-03, -6.0282e-02,\n",
       "            5.5965e-02,  5.3406e-02, -5.5433e-02, -1.1382e-01,  8.9518e-02,\n",
       "           -2.2691e-02, -5.9046e-02,  6.0146e-02,  3.9642e-02, -6.3009e-02,\n",
       "           -5.2582e-02,  2.5829e-02,  8.9769e-02, -2.7016e-02,  7.8205e-02,\n",
       "            1.2091e-01,  1.1181e-01,  1.1154e-01, -3.5277e-02, -5.7550e-02,\n",
       "            3.2280e-02,  1.6222e-02,  2.8114e-02,  4.0406e-02, -7.0599e-02,\n",
       "           -1.0098e-01, -1.8132e-02,  2.4257e-02, -3.9721e-02, -8.2378e-03,\n",
       "           -4.4069e-02,  2.0135e-03,  2.9513e-03,  1.9616e-02,  5.7899e-04,\n",
       "            8.6723e-02, -8.7020e-03, -3.9232e-02,  1.0774e-01, -8.1918e-02,\n",
       "            1.0194e-01,  1.8069e-02, -9.1404e-02, -9.1760e-02, -1.5025e-01,\n",
       "           -5.9896e-03,  1.0701e-01, -6.1355e-02,  9.0845e-02, -7.9668e-02,\n",
       "            1.1232e-01, -5.4238e-02, -5.0937e-02, -2.9023e-02, -6.7254e-02,\n",
       "           -7.6717e-02,  8.8326e-02,  4.8121e-02,  5.0910e-02, -8.4435e-02,\n",
       "            1.0692e-01,  4.1978e-02, -8.9154e-02,  6.6704e-02, -9.5948e-02,\n",
       "           -2.0597e-02, -6.7272e-02, -4.4929e-02,  1.7174e-02,  1.0990e-01,\n",
       "           -1.9319e-02,  1.9334e-02,  1.6974e-02,  8.0835e-02, -7.7561e-03,\n",
       "            3.5509e-02, -3.9221e-02, -1.1879e-02,  5.2793e-03, -1.9482e-03,\n",
       "           -1.0481e-01,  7.6393e-02, -6.0108e-02, -4.1834e-03,  6.1402e-02,\n",
       "            4.8420e-02, -3.4744e-02, -3.9269e-02, -7.7178e-02,  8.6874e-02,\n",
       "           -6.9591e-04, -3.7076e-02, -8.1922e-02, -4.6441e-02, -2.3260e-02,\n",
       "            5.4650e-02, -7.8472e-02,  2.5160e-02,  5.3016e-02, -2.8029e-02,\n",
       "            2.3323e-02,  8.6092e-02,  7.5978e-03, -1.4312e-02,  1.1734e-01,\n",
       "            1.3026e-01,  1.7064e-02, -2.3875e-02,  2.7004e-03, -1.2720e-01,\n",
       "            3.3334e-02, -5.6761e-02, -3.2339e-02, -7.0299e-02, -7.9858e-03,\n",
       "            7.4774e-02, -2.2271e-02, -1.1919e-01, -1.4687e-01,  5.3717e-03,\n",
       "           -6.1701e-02,  4.5445e-02,  6.3784e-03, -4.0438e-02, -5.9611e-02,\n",
       "           -6.1935e-02,  6.8031e-02,  4.7659e-02, -2.1682e-03,  7.8582e-02,\n",
       "            3.9164e-02,  1.1563e-02, -7.3522e-02, -3.9666e-02, -4.6967e-02,\n",
       "            1.1649e-02, -1.2453e-03, -3.1039e-02, -3.7071e-02,  4.9368e-02,\n",
       "            1.3186e-02, -8.7588e-03,  1.2204e-01, -9.9624e-02, -8.2977e-02,\n",
       "            1.0637e-01, -1.6035e-02, -3.1130e-02, -4.9938e-02, -2.1415e-03,\n",
       "            5.8466e-02, -3.2159e-03,  1.9857e-02, -1.2417e-01,  3.5502e-02,\n",
       "           -2.3893e-02, -3.3012e-02, -8.3745e-02,  9.7216e-02,  1.1065e-02,\n",
       "           -8.4888e-02, -1.2443e-03,  6.4335e-03, -4.2979e-02, -4.7702e-02,\n",
       "            9.5923e-02, -6.7138e-02,  1.4406e-02, -2.6066e-02,  4.9101e-02,\n",
       "           -3.1273e-02,  7.5370e-02, -1.5743e-02, -3.2779e-02, -4.7082e-02,\n",
       "           -1.5601e-01,  1.7424e-02,  1.4169e-01, -3.6000e-02, -8.4731e-02,\n",
       "            3.5253e-03,  3.8916e-02, -1.6844e-02,  1.8722e-02, -2.4873e-02,\n",
       "           -1.6093e-02,  2.3952e-02,  3.0343e-03,  7.7883e-02, -1.7375e-02,\n",
       "            6.7626e-03,  4.1278e-03, -5.9583e-02, -9.2927e-02,  1.2925e-01,\n",
       "            1.0431e-02,  3.0469e-02, -3.5864e-02,  3.1981e-02, -5.2217e-02,\n",
       "           -7.8222e-02, -4.4398e-02, -5.6486e-02,  2.5312e-02, -4.7000e-02,\n",
       "           -4.1476e-02, -6.0991e-03, -9.0483e-02, -4.1105e-02,  3.7298e-02,\n",
       "            1.0203e-01]], device='cuda:0', grad_fn=<ViewBackward>), None],\n",
       " [tensor([[-7.5658e-02,  5.8357e-02,  1.5442e-02, -7.6628e-03,  9.9435e-02,\n",
       "            2.4130e-03,  4.3831e-02,  1.3985e-02, -5.1628e-02,  3.1727e-02,\n",
       "            1.5352e-02,  3.4404e-02,  8.6421e-02, -3.3026e-02,  2.6552e-02,\n",
       "           -3.6752e-02,  6.5100e-02,  6.9933e-02, -9.8509e-02, -1.0327e-01,\n",
       "            4.1464e-02, -1.0296e-02, -2.1406e-02,  3.2631e-02, -3.6033e-02,\n",
       "           -1.6451e-01,  1.1924e-01, -4.5922e-02, -5.6380e-02,  8.9856e-02,\n",
       "            6.8436e-02,  7.6546e-02, -6.7120e-02, -6.1194e-02,  2.1932e-02,\n",
       "           -6.2909e-02, -4.2845e-02, -6.0889e-02, -2.8889e-02, -9.3320e-02,\n",
       "           -9.0441e-02,  6.3612e-02,  4.4647e-03,  6.7011e-03, -8.5309e-02,\n",
       "            2.2906e-02,  5.9241e-02, -4.9961e-02, -2.5853e-02, -3.4145e-02,\n",
       "           -7.0855e-02, -3.7283e-02,  1.0402e-02, -5.0528e-04, -3.1707e-02,\n",
       "            9.1116e-02,  4.2293e-02,  9.5432e-02,  3.9348e-02,  9.6384e-02,\n",
       "           -9.1544e-03,  1.4140e-01,  1.0451e-01,  3.2017e-02,  6.4265e-02,\n",
       "            5.0578e-02, -5.7497e-02,  5.7785e-02,  4.6992e-02,  3.6222e-02,\n",
       "           -5.1095e-02, -6.2722e-03,  1.4142e-02,  4.2849e-02, -7.8522e-02,\n",
       "           -9.8923e-02,  6.7524e-02, -1.1961e-01, -2.7276e-02,  5.0698e-02,\n",
       "            1.3865e-01,  1.5164e-03, -7.1561e-03,  5.1352e-02, -7.7970e-02,\n",
       "            1.1073e-01,  1.2596e-02, -9.6913e-02, -3.2164e-02, -1.9580e-02,\n",
       "           -4.2639e-02,  5.8990e-02, -1.9022e-02, -1.5092e-02, -1.2489e-01,\n",
       "            9.2309e-02, -9.9661e-02, -6.2376e-03, -1.5848e-03, -8.6934e-02,\n",
       "           -1.1083e-01,  1.1026e-02, -3.7098e-02,  4.3134e-02, -8.8618e-02,\n",
       "            1.0466e-01, -3.3725e-02, -1.3535e-01,  4.2262e-02, -5.4934e-02,\n",
       "            3.0495e-03, -8.3213e-02,  3.1159e-03,  1.3076e-02,  7.2075e-02,\n",
       "            9.5666e-05,  5.4977e-02,  4.4428e-02,  7.1213e-02, -4.0273e-02,\n",
       "           -2.9918e-02,  6.1812e-02, -4.0570e-02, -2.5474e-02, -3.4242e-02,\n",
       "           -2.6706e-02,  9.1024e-02,  6.2098e-02,  7.3857e-03,  5.4940e-02,\n",
       "            4.1127e-02, -8.4998e-02, -9.4223e-02, -5.0898e-02,  3.8397e-02,\n",
       "            1.6038e-02, -9.3560e-02, -8.1324e-02, -1.6886e-02, -6.2605e-02,\n",
       "            5.6361e-02, -1.5168e-02,  2.6032e-02, -1.0750e-02,  7.0932e-02,\n",
       "           -2.8003e-03,  7.8527e-02, -4.4744e-02, -1.4008e-02,  3.7284e-02,\n",
       "            1.4168e-01,  5.2676e-02,  1.4194e-02,  4.3147e-02, -1.2177e-01,\n",
       "            6.7053e-02, -8.0556e-02, -4.4579e-02, -5.3740e-02,  1.1435e-02,\n",
       "            5.2308e-03, -5.4416e-03, -7.4888e-02, -6.3413e-02,  3.6048e-02,\n",
       "           -3.9544e-02,  1.0700e-01, -6.1611e-02,  4.1685e-02, -8.6968e-02,\n",
       "           -4.4941e-02,  2.2725e-02,  7.4838e-02, -4.4316e-02,  3.1683e-02,\n",
       "           -2.8111e-02, -6.7044e-02,  5.6995e-03, -1.8018e-02, -5.4867e-02,\n",
       "            5.9826e-02,  6.8344e-02,  3.8481e-02, -9.1655e-02,  1.2809e-02,\n",
       "           -1.6461e-02,  8.6046e-02,  7.0854e-02, -1.0940e-01, -2.7584e-02,\n",
       "            1.2021e-01,  2.7976e-02, -4.8374e-02, -1.8518e-02,  7.9390e-02,\n",
       "            4.7630e-02, -1.4942e-02,  1.9022e-02, -4.5674e-02, -1.3821e-01,\n",
       "           -1.0829e-01,  4.1827e-02, -1.2269e-02,  1.0490e-01, -1.4414e-02,\n",
       "           -9.4152e-02, -3.2204e-02,  5.0789e-02, -1.4657e-01, -1.0805e-02,\n",
       "            1.1059e-01, -2.2947e-02, -2.9344e-03, -1.0334e-01,  4.7184e-03,\n",
       "            2.0583e-02,  8.4721e-03, -3.0984e-02, -1.2248e-01, -7.7871e-02,\n",
       "           -1.1181e-01, -1.6668e-03, -3.6545e-02,  1.9314e-02,  7.4319e-03,\n",
       "           -6.3031e-02,  3.2881e-02, -5.8839e-03,  6.8273e-02,  3.1566e-03,\n",
       "           -3.6574e-03, -3.5473e-02,  2.3190e-02,  5.8380e-02,  1.8585e-02,\n",
       "            7.5817e-02,  1.6115e-02, -3.6141e-02, -3.0181e-02,  5.6958e-02,\n",
       "           -4.3694e-03,  3.8451e-02, -9.6169e-02, -9.1970e-02, -3.1302e-02,\n",
       "           -8.2370e-02, -8.3748e-02, -5.2881e-02, -5.4151e-02, -6.4248e-03,\n",
       "           -1.2688e-02,  2.2469e-02, -8.5643e-02, -9.9777e-02,  4.4091e-02,\n",
       "            4.6093e-02],\n",
       "          [-7.5658e-02,  5.8357e-02,  1.5442e-02, -7.6628e-03,  9.9435e-02,\n",
       "            2.4130e-03,  4.3831e-02,  1.3985e-02, -5.1628e-02,  3.1727e-02,\n",
       "            1.5352e-02,  3.4404e-02,  8.6421e-02, -3.3026e-02,  2.6552e-02,\n",
       "           -3.6752e-02,  6.5100e-02,  6.9933e-02, -9.8509e-02, -1.0327e-01,\n",
       "            4.1464e-02, -1.0296e-02, -2.1406e-02,  3.2631e-02, -3.6033e-02,\n",
       "           -1.6451e-01,  1.1924e-01, -4.5922e-02, -5.6380e-02,  8.9856e-02,\n",
       "            6.8436e-02,  7.6546e-02, -6.7120e-02, -6.1194e-02,  2.1932e-02,\n",
       "           -6.2909e-02, -4.2845e-02, -6.0889e-02, -2.8889e-02, -9.3320e-02,\n",
       "           -9.0441e-02,  6.3612e-02,  4.4647e-03,  6.7011e-03, -8.5309e-02,\n",
       "            2.2906e-02,  5.9241e-02, -4.9961e-02, -2.5853e-02, -3.4145e-02,\n",
       "           -7.0855e-02, -3.7283e-02,  1.0402e-02, -5.0528e-04, -3.1707e-02,\n",
       "            9.1116e-02,  4.2293e-02,  9.5432e-02,  3.9348e-02,  9.6384e-02,\n",
       "           -9.1544e-03,  1.4140e-01,  1.0451e-01,  3.2017e-02,  6.4265e-02,\n",
       "            5.0578e-02, -5.7497e-02,  5.7785e-02,  4.6992e-02,  3.6222e-02,\n",
       "           -5.1095e-02, -6.2722e-03,  1.4142e-02,  4.2849e-02, -7.8522e-02,\n",
       "           -9.8923e-02,  6.7524e-02, -1.1961e-01, -2.7276e-02,  5.0698e-02,\n",
       "            1.3865e-01,  1.5164e-03, -7.1561e-03,  5.1352e-02, -7.7970e-02,\n",
       "            1.1073e-01,  1.2596e-02, -9.6913e-02, -3.2164e-02, -1.9580e-02,\n",
       "           -4.2639e-02,  5.8990e-02, -1.9022e-02, -1.5092e-02, -1.2489e-01,\n",
       "            9.2309e-02, -9.9661e-02, -6.2376e-03, -1.5848e-03, -8.6934e-02,\n",
       "           -1.1083e-01,  1.1026e-02, -3.7098e-02,  4.3134e-02, -8.8618e-02,\n",
       "            1.0466e-01, -3.3725e-02, -1.3535e-01,  4.2262e-02, -5.4934e-02,\n",
       "            3.0495e-03, -8.3213e-02,  3.1159e-03,  1.3076e-02,  7.2075e-02,\n",
       "            9.5666e-05,  5.4977e-02,  4.4428e-02,  7.1213e-02, -4.0273e-02,\n",
       "           -2.9918e-02,  6.1812e-02, -4.0570e-02, -2.5474e-02, -3.4242e-02,\n",
       "           -2.6706e-02,  9.1024e-02,  6.2098e-02,  7.3857e-03,  5.4940e-02,\n",
       "            4.1127e-02, -8.4998e-02, -9.4223e-02, -5.0898e-02,  3.8397e-02,\n",
       "            1.6038e-02, -9.3560e-02, -8.1324e-02, -1.6886e-02, -6.2605e-02,\n",
       "            5.6361e-02, -1.5168e-02,  2.6032e-02, -1.0750e-02,  7.0932e-02,\n",
       "           -2.8003e-03,  7.8527e-02, -4.4744e-02, -1.4008e-02,  3.7284e-02,\n",
       "            1.4168e-01,  5.2676e-02,  1.4194e-02,  4.3147e-02, -1.2177e-01,\n",
       "            6.7053e-02, -8.0556e-02, -4.4579e-02, -5.3740e-02,  1.1435e-02,\n",
       "            5.2308e-03, -5.4416e-03, -7.4888e-02, -6.3413e-02,  3.6048e-02,\n",
       "           -3.9544e-02,  1.0700e-01, -6.1611e-02,  4.1685e-02, -8.6968e-02,\n",
       "           -4.4941e-02,  2.2725e-02,  7.4838e-02, -4.4316e-02,  3.1683e-02,\n",
       "           -2.8111e-02, -6.7044e-02,  5.6995e-03, -1.8018e-02, -5.4867e-02,\n",
       "            5.9826e-02,  6.8344e-02,  3.8481e-02, -9.1655e-02,  1.2809e-02,\n",
       "           -1.6461e-02,  8.6046e-02,  7.0854e-02, -1.0940e-01, -2.7584e-02,\n",
       "            1.2021e-01,  2.7976e-02, -4.8374e-02, -1.8518e-02,  7.9390e-02,\n",
       "            4.7630e-02, -1.4942e-02,  1.9022e-02, -4.5674e-02, -1.3821e-01,\n",
       "           -1.0829e-01,  4.1827e-02, -1.2269e-02,  1.0490e-01, -1.4414e-02,\n",
       "           -9.4152e-02, -3.2204e-02,  5.0789e-02, -1.4657e-01, -1.0805e-02,\n",
       "            1.1059e-01, -2.2947e-02, -2.9344e-03, -1.0334e-01,  4.7184e-03,\n",
       "            2.0583e-02,  8.4721e-03, -3.0984e-02, -1.2248e-01, -7.7871e-02,\n",
       "           -1.1181e-01, -1.6668e-03, -3.6545e-02,  1.9314e-02,  7.4319e-03,\n",
       "           -6.3031e-02,  3.2881e-02, -5.8839e-03,  6.8273e-02,  3.1566e-03,\n",
       "           -3.6574e-03, -3.5473e-02,  2.3190e-02,  5.8380e-02,  1.8585e-02,\n",
       "            7.5817e-02,  1.6115e-02, -3.6141e-02, -3.0181e-02,  5.6958e-02,\n",
       "           -4.3694e-03,  3.8451e-02, -9.6169e-02, -9.1970e-02, -3.1302e-02,\n",
       "           -8.2370e-02, -8.3748e-02, -5.2881e-02, -5.4151e-02, -6.4248e-03,\n",
       "           -1.2688e-02,  2.2469e-02, -8.5643e-02, -9.9777e-02,  4.4091e-02,\n",
       "            4.6093e-02]], device='cuda:0', grad_fn=<ViewBackward>), None],\n",
       " [tensor([[-0.0035,  0.1055, -0.0185, -0.0212,  0.0787,  0.0505,  0.0265, -0.0505,\n",
       "           -0.0348,  0.0145, -0.0339,  0.0019,  0.0456, -0.0144,  0.0148, -0.0170,\n",
       "            0.0325,  0.1026, -0.0911, -0.1111,  0.0709, -0.0100,  0.0085,  0.0237,\n",
       "            0.0239, -0.1760,  0.0539, -0.0665, -0.0754,  0.0108,  0.0174,  0.0362,\n",
       "           -0.0748, -0.0542, -0.0405, -0.1511,  0.0239, -0.0175,  0.0556, -0.0539,\n",
       "           -0.1160,  0.0259,  0.0154,  0.0231, -0.1079,  0.0321, -0.0215, -0.0910,\n",
       "           -0.0438, -0.0387, -0.0212, -0.0546,  0.0369,  0.0312, -0.0564,  0.0482,\n",
       "            0.0432,  0.0940,  0.0208,  0.1065,  0.0550,  0.0712,  0.0807,  0.0216,\n",
       "            0.0012,  0.0624, -0.0112, -0.0242,  0.0184, -0.0099, -0.0613, -0.0041,\n",
       "            0.0313,  0.0470, -0.0723, -0.0598,  0.0055, -0.0861, -0.0372,  0.1054,\n",
       "            0.1015,  0.0770,  0.0552,  0.1588, -0.0881,  0.0629, -0.0803, -0.0197,\n",
       "            0.0381,  0.0748, -0.0846,  0.0828, -0.0193, -0.0284, -0.1051,  0.0567,\n",
       "           -0.0580, -0.0196,  0.0230, -0.0902, -0.0603,  0.0121,  0.0667,  0.0244,\n",
       "           -0.0122,  0.0464, -0.0253, -0.0844,  0.0111, -0.0780,  0.0501, -0.0353,\n",
       "            0.0260,  0.0754,  0.0394,  0.0235,  0.0004, -0.0078,  0.1047, -0.0667,\n",
       "           -0.0606, -0.0407, -0.0439, -0.0525,  0.0233, -0.0680,  0.1423,  0.0402,\n",
       "            0.0312,  0.0354,  0.0711, -0.1034, -0.1175, -0.1010, -0.0414, -0.0156,\n",
       "           -0.0608, -0.0601,  0.0174, -0.0195, -0.0346, -0.0008,  0.0729, -0.0668,\n",
       "            0.0262, -0.0035,  0.1251,  0.0075,  0.0413,  0.0282,  0.0725,  0.0232,\n",
       "            0.0145,  0.0670, -0.1074,  0.0413, -0.0717, -0.0423, -0.1037, -0.1114,\n",
       "           -0.0135,  0.0113, -0.0786, -0.0036,  0.1090,  0.0237,  0.0927, -0.0376,\n",
       "            0.0369, -0.0904,  0.0410,  0.1198,  0.0962,  0.0517,  0.0188, -0.0403,\n",
       "           -0.0395,  0.0284, -0.1132, -0.1423,  0.0203,  0.0212,  0.0760, -0.0692,\n",
       "            0.0385,  0.0195,  0.0330,  0.1427, -0.0581,  0.0544,  0.0742, -0.0205,\n",
       "           -0.0722,  0.0190, -0.0184, -0.0744,  0.0603,  0.0408, -0.0628, -0.0866,\n",
       "           -0.0472,  0.0770, -0.0540,  0.1110,  0.0366, -0.0334, -0.0102,  0.0562,\n",
       "           -0.0365,  0.0350,  0.0357,  0.0134, -0.0162, -0.1030,  0.0118, -0.0039,\n",
       "            0.0569,  0.0039, -0.0887, -0.0337, -0.1564, -0.0255, -0.0018, -0.0469,\n",
       "           -0.0166, -0.0116,  0.0763,  0.0041,  0.0913,  0.0275,  0.0342, -0.0511,\n",
       "           -0.0095,  0.0574,  0.0355,  0.0810, -0.0097, -0.0335, -0.0918,  0.0550,\n",
       "            0.0138,  0.0120, -0.1565, -0.0174, -0.0658, -0.0879, -0.0535,  0.0151,\n",
       "           -0.0261, -0.0437,  0.0397,  0.0417, -0.1023, -0.1247, -0.0390,  0.0193],\n",
       "          [-0.0035,  0.1055, -0.0185, -0.0212,  0.0787,  0.0505,  0.0265, -0.0505,\n",
       "           -0.0348,  0.0145, -0.0339,  0.0019,  0.0456, -0.0144,  0.0148, -0.0170,\n",
       "            0.0325,  0.1026, -0.0911, -0.1111,  0.0709, -0.0100,  0.0085,  0.0237,\n",
       "            0.0239, -0.1760,  0.0539, -0.0665, -0.0754,  0.0108,  0.0174,  0.0362,\n",
       "           -0.0748, -0.0542, -0.0405, -0.1511,  0.0239, -0.0175,  0.0556, -0.0539,\n",
       "           -0.1160,  0.0259,  0.0154,  0.0231, -0.1079,  0.0321, -0.0215, -0.0910,\n",
       "           -0.0438, -0.0387, -0.0212, -0.0546,  0.0369,  0.0312, -0.0564,  0.0482,\n",
       "            0.0432,  0.0940,  0.0208,  0.1065,  0.0550,  0.0712,  0.0807,  0.0216,\n",
       "            0.0012,  0.0624, -0.0112, -0.0242,  0.0184, -0.0099, -0.0613, -0.0041,\n",
       "            0.0313,  0.0470, -0.0723, -0.0598,  0.0055, -0.0861, -0.0372,  0.1054,\n",
       "            0.1015,  0.0770,  0.0552,  0.1588, -0.0881,  0.0629, -0.0803, -0.0197,\n",
       "            0.0381,  0.0748, -0.0846,  0.0828, -0.0193, -0.0284, -0.1051,  0.0567,\n",
       "           -0.0580, -0.0196,  0.0230, -0.0902, -0.0603,  0.0121,  0.0667,  0.0244,\n",
       "           -0.0122,  0.0464, -0.0253, -0.0844,  0.0111, -0.0780,  0.0501, -0.0353,\n",
       "            0.0260,  0.0754,  0.0394,  0.0235,  0.0004, -0.0078,  0.1047, -0.0667,\n",
       "           -0.0606, -0.0407, -0.0439, -0.0525,  0.0233, -0.0680,  0.1423,  0.0402,\n",
       "            0.0312,  0.0354,  0.0711, -0.1034, -0.1175, -0.1010, -0.0414, -0.0156,\n",
       "           -0.0608, -0.0601,  0.0174, -0.0195, -0.0346, -0.0008,  0.0729, -0.0668,\n",
       "            0.0262, -0.0035,  0.1251,  0.0075,  0.0413,  0.0282,  0.0725,  0.0232,\n",
       "            0.0145,  0.0670, -0.1074,  0.0413, -0.0717, -0.0423, -0.1037, -0.1114,\n",
       "           -0.0135,  0.0113, -0.0786, -0.0036,  0.1090,  0.0237,  0.0927, -0.0376,\n",
       "            0.0369, -0.0904,  0.0410,  0.1198,  0.0962,  0.0517,  0.0188, -0.0403,\n",
       "           -0.0395,  0.0284, -0.1132, -0.1423,  0.0203,  0.0212,  0.0760, -0.0692,\n",
       "            0.0385,  0.0195,  0.0330,  0.1427, -0.0581,  0.0544,  0.0742, -0.0205,\n",
       "           -0.0722,  0.0190, -0.0184, -0.0744,  0.0603,  0.0408, -0.0628, -0.0866,\n",
       "           -0.0472,  0.0770, -0.0540,  0.1110,  0.0366, -0.0334, -0.0102,  0.0562,\n",
       "           -0.0365,  0.0350,  0.0357,  0.0134, -0.0162, -0.1030,  0.0118, -0.0039,\n",
       "            0.0569,  0.0039, -0.0887, -0.0337, -0.1564, -0.0255, -0.0018, -0.0469,\n",
       "           -0.0166, -0.0116,  0.0763,  0.0041,  0.0913,  0.0275,  0.0342, -0.0511,\n",
       "           -0.0095,  0.0574,  0.0355,  0.0810, -0.0097, -0.0335, -0.0918,  0.0550,\n",
       "            0.0138,  0.0120, -0.1565, -0.0174, -0.0658, -0.0879, -0.0535,  0.0151,\n",
       "           -0.0261, -0.0437,  0.0397,  0.0417, -0.1023, -0.1247, -0.0390,  0.0193]],\n",
       "         device='cuda:0', grad_fn=<ViewBackward>), None]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearranged_output_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disco",
   "language": "python",
   "name": "disco"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
