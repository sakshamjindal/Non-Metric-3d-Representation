{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "with open(\"../feed_dict.json\",\"rb\") as file:\n",
    "    feed_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict_q = feed_dict\n",
    "feed_dict_k = feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "feed_dict_q[\"view\"] = torch.rand((feed_dict[\"image\"].size(0),1,7))\n",
    "feed_dict_k[\"view\"] = torch.rand((feed_dict[\"image\"].size(0),1,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from core.scene_graph.scene_graph import SceneGraph\n",
    "from torchvision.models import resnet34\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dim = 256):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dim = dim\n",
    "        self.resnet = resnet34(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(self.resnet.children())[:-3])\n",
    "        \n",
    "        self.scene_graph = SceneGraph(feature_dim=self.dim, \n",
    "                                 output_dims=[self.dim,self.dim],\n",
    "                                 downsample_rate=16)\n",
    "        \n",
    "        \n",
    "    def forward(self,feed_dict):\n",
    "        \n",
    "        num_batch = feed_dict[\"images\"].shape[0]\n",
    "        num_total_nodes = feed_dict[\"objects_length\"].sum().item()\n",
    "        \n",
    "        image_features = self.feature_extractor(feed_dict[\"images\"])\n",
    "        outputs = self.scene_graph(image_features, feed_dict[\"objects\"], feed_dict[\"objects_length\"])\n",
    "        \n",
    "        node_features = output[0][0]\n",
    "        for num in range(1,num_batch):\n",
    "            node_features = torch.cat([node_features, output[num][0]], dim =0)\n",
    "        \n",
    "        # To be implemented\n",
    "        spatial_features = None\n",
    "        \n",
    "        return outputs, node_features, spatial_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, node_features, spatial_features = encoder(feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disco",
   "language": "python",
   "name": "disco"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
