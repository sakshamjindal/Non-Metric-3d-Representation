{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import builtins\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from core.model.model import MoCo\n",
    "from core.dataloader import GQNDataset_pdisco, collate_boxes\n",
    "from core.utils import compute_features, run_kmeans, AverageMeter, ProgressMeter, adjust_learning_rate, accuracy, save_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--exp-dir'], dest='exp_dir', nargs=None, const=None, default='experiment_pcl', type=<class 'str'>, choices=None, help='experiment directory to store tb logs and checkpoints', metavar=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Relational 2d Training')\n",
    "# parser.add_argument('data', metavar='DIR',\n",
    "#                     help='path to datasets root directory')\n",
    "parser.add_argument('-j', '--num-worker', default=1, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 1)')\n",
    "parser.add_argument('--epochs', default=200, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('-b', '--batch-size', default=16, type=int,\n",
    "                    metavar='N',\n",
    "                    help='mini-batch size (default: 16), this is the total '\n",
    "                         'batch size of all GPUs on the current node when '\n",
    "                         'using Data Parallel or Distributed Data Parallel')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.03, type=float,\n",
    "                    metavar='LR', help='initial learning rate', dest='lr')\n",
    "parser.add_argument('--schedule', default=[120, 160], nargs='*', type=int,\n",
    "                    help='learning rate schedule (when to drop lr by 10x)')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum of SGD solver')\n",
    "parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)',\n",
    "                    dest='weight_decay')\n",
    "parser.add_argument('-p', '--print-freq', default=100, type=int,\n",
    "                    metavar='N', help='print iter frequency (default: 100)')\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "\n",
    "parser.add_argument('--seed', default=None, type=int,\n",
    "                    help='seed for initializing training. ')\n",
    "parser.add_argument(\"--gpu\", type=int, nargs='+', default=None, help='GPU id to use.')\n",
    "parser.add_argument('--warmup-epoch', default=10, type=int,\n",
    "                    help='number of warm-up epochs to only train with InfoNCE loss')\n",
    "parser.add_argument('--cos', action='store_true',\n",
    "                    help='use cosine lr schedule')\n",
    "parser.add_argument('--exp-dir', default='experiment_pcl', type=str,\n",
    "                    help='experiment directory to store tb logs and checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('../tb_logs'):\n",
    "    os.makedirs('../tb_logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def setup_tb(exp_name):\n",
    "    tb_directory = os.path.join('../tb_logs', exp_name)\n",
    "    return SummaryWriter(tb_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def run_training(args):\n",
    "    \n",
    "#     parser = argparse.ArgumentParser(description='Relational 2d Training')\n",
    "    \n",
    "#     if default_args:\n",
    "#         args = parser.parse_args(default_args)\n",
    "#     else:\n",
    "#         args = parser.parse_args()\n",
    "        \n",
    "    tb_logger = setup_tb(args.exp_dir)\n",
    "    \n",
    "    if args.seed is not None:\n",
    "        random.seed(args.seed)\n",
    "        torch.manual_seed(args.seed)\n",
    "        cudnn.deterministic = True\n",
    "        warnings.warn('You have chosen to seed training. '\n",
    "                      'This will turn on the CUDNN deterministic setting, '\n",
    "                      'which can slow down your training considerably! '\n",
    "                      'You may see unexpected behavior when restarting '\n",
    "                      'from checkpoints.')\n",
    "\n",
    "    if args.gpu is not None:\n",
    "        warnings.warn('You have chosen a specific GPU. This will completely '\n",
    "                      'disable data parallelism.')\n",
    "    \n",
    "    if not os.path.exists(args.exp_dir):\n",
    "        os.mkdir(args.exp_dir)\n",
    "    if not os.path.exists(os.path.join('../tb_logs',args.exp_dir)):\n",
    "        os.mkdir(os.path.join('../tb_logs', args.exp_dir))\n",
    "    \n",
    "    ngpus_per_node = torch.cuda.device_count()\n",
    "    \n",
    "    gpu_devices = ','.join([str(id) for id in range(ngpus_per_node)])\n",
    "    #os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_devices\n",
    "    \n",
    "    best_acc = 0\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    print('==> Preparing data..')\n",
    "    \n",
    "    train_dataset = GQNDataset_pdisco(root_dir='/home/mprabhud/dataset/clevr_veggies/npys/be_lt.txt')\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, collate_fn=collate_boxes)\n",
    "\n",
    "    print('==> Making model..')\n",
    "\n",
    "    model = MoCo()\n",
    "    #model = nn.DataParallel(model)\n",
    "    model = model.to(device)\n",
    "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print('The number of parameters of model is', num_params)\n",
    "    \n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                                momentum=args.momentum,\n",
    "                                weight_decay=args.weight_decay)\n",
    "    \n",
    "    # optionally resume from a checkpoint\n",
    "    if args.resume:\n",
    "        if os.path.isfile(args.resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "            checkpoint = torch.load(args.resume)\n",
    "#             else:\n",
    "#                 # Map model to be loaded to specified single gpu.\n",
    "#                 loc = 'cuda:{}'.format(args.gpu)\n",
    "#                 checkpoint = torch.load(args.resume, map_location=loc)\n",
    "            args.start_epoch = checkpoint['epoch']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args.resume, checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "            \n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "\n",
    "        cluster_result = None\n",
    "        \n",
    "        if epoch>=args.warmup_epoch:\n",
    "            # compute momentum features for center-cropped images\n",
    "            features = compute_features(eval_loader, model, args)         \n",
    "\n",
    "            # placeholder for clustering result\n",
    "            cluster_result = {'im2cluster':[],'centroids':[],'density':[]}\n",
    "            for num_cluster in args.num_cluster:\n",
    "                cluster_result['im2cluster'].append(torch.zeros(len(eval_dataset),dtype=torch.long).cuda())\n",
    "                cluster_result['centroids'].append(torch.zeros(int(num_cluster),args.low_dim).cuda())\n",
    "                cluster_result['density'].append(torch.zeros(int(num_cluster)).cuda()) \n",
    "\n",
    "            features[torch.norm(features,dim=1)>1.5] /= 2 #account for the few samples that are computed twice  \n",
    "            features = features.numpy()\n",
    "            cluster_result = run_kmeans(features,args)  #run kmeans clustering on master node\n",
    "                # save the clustering result\n",
    "                # torch.save(cluster_result,os.path.join(args.exp_dir, 'clusters_%d'%epoch))  \n",
    "\n",
    "        adjust_learning_rate(optimizer, epoch, args)\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch, args, cluster_result, tb_logger)\n",
    "        break\n",
    "        if (epoch+1)%5==0:\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch + 1,\n",
    "                'arch': args.arch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer' : optimizer.state_dict(),\n",
    "            }, is_best=False, filename='{}/checkpoint.pth.tar'.format(args.exp_dir))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch, args, cluster_result=None, tb_logger=None):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    acc_inst = AverageMeter('Acc@Inst', ':6.2f')   \n",
    "    acc_proto = AverageMeter('Acc@Proto', ':6.2f')\n",
    "    \n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, acc_inst, acc_proto],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (feed_dict_q, feed_dict_k, metadata) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)   \n",
    "                \n",
    "        # compute output\n",
    "        index = metadata[\"scene_number\"]\n",
    "        output, target, output_proto, target_proto = model(feed_dict_q, feed_dict_k, metadata, cluster_result=cluster_result, index=index)\n",
    "        \n",
    "        # InfoNCE loss\n",
    "        loss = criterion(output, target)  \n",
    "        \n",
    "        # ProtoNCE loss\n",
    "        if output_proto is not None:\n",
    "            loss_proto = 0\n",
    "            for proto_out,proto_target in zip(output_proto, target_proto):\n",
    "                loss_proto += criterion(proto_out, proto_target)  \n",
    "                accp = accuracy(proto_out, proto_target)[0] \n",
    "                acc_proto.update(accp[0], args.batch_size)\n",
    "                \n",
    "            # average loss across all sets of prototypes\n",
    "            loss_proto /= len(args.num_cluster) \n",
    "            loss += loss_proto   \n",
    "\n",
    "        losses.update(loss.item(), args.batch_size)\n",
    "        acc = accuracy(output, target)[0] \n",
    "        acc_inst.update(acc[0], args.batch_size)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    " \n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            progress.display(i)\n",
    "        break\n",
    "\n",
    "    print(\"Logging to TB....\")\n",
    "    tb_logger.add_scalar('Train Acc Inst', acc_inst.avg, epoch)\n",
    "    tb_logger.add_scalar('Train Acc Prototype', acc_proto.avg, epoch)\n",
    "    tb_logger.add_scalar('Train Total Loss', losses.avg, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Initialised..... 27495  files...\n",
      "==> Making model..\n",
      "The number of parameters of model is 29279144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mprabhud/ishita/non-metric_3d_representation/core/dataloader.py:145: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  boxes_q = utils_disco.get_bounding_boxes(torch.tensor(query_image), boxes, camXs_T_origin_q, pix_T_camXs_q, num_boxes)\n",
      "/home/mprabhud/ishita/non-metric_3d_representation/core/utils_disco.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  xmin,ymin,zmin,xmax,ymax,zmax = torch.unbind(torch.tensor(aligned_boxes), dim=-1)\n",
      "/home/mprabhud/ishita/non-metric_3d_representation/core/dataloader.py:150: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  boxes_k = utils_disco.get_bounding_boxes(torch.tensor(key_image), boxes, camXs_T_origin_k, pix_T_camXs_k, num_boxes)\n",
      "/home/mprabhud/ishita/non-metric_3d_representation/core/dataloader.py:164: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(query_image), num_boxes, torch.tensor(boxes_q), torch.tensor(key_image), num_boxes, torch.tensor(boxes_k), scene_num, key_img_view, torch.tensor(pix_T_cams_raw), torch.tensor(camR_T_origin_raw), torch.tensor(origin_T_camXs_raw), torch.tensor(rel_viewpoint)\n",
      "/home/mprabhud/ishita/non-metric_3d_representation/core/dataloader.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  metadata = {\"scene_number\":scene_num, \"key_image_index\":key_img_view, \"pix_T_cams_raw\":torch.tensor(pix_T_cams_raw).cuda(), \"camR_T_origin_raw\":torch.tensor(camR_T_origin_raw).cuda(), \"origin_T_camXs_raw\":torch.tensor(origin_T_camXs_raw).cuda(), \"rel_viewpoint\":torch.tensor(gt_egomotion).cuda()}\n",
      "/home/mprabhud/ishita/non-metric_3d_representation/core/dataloader.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  feed_dict_q = {\"images\":torch.tensor(query_image).cuda(), \"objects\":num_boxes_q, \"objects_boxes\":torch.tensor(object_boxes_q).cuda()}\n",
      "/home/mprabhud/ishita/non-metric_3d_representation/core/dataloader.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  feed_dict_k = {\"images\":torch.tensor(key_image).cuda(), \"objects\":num_boxes_k, \"objects_boxes\":torch.tensor(object_boxes_k).cuda()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viewpoint Transformation of Node feature vectors\n",
      "Node: Pose with Node Concat :  Batch Ind: 0\n",
      "Node: Pose with Node Concat :  Batch Ind: 1\n",
      "Node: Pose with Node Concat :  Batch Ind: 2\n",
      "Node: Pose with Node Concat :  Batch Ind: 3\n",
      "Node: Pose with Node Concat :  Batch Ind: 4\n",
      "Node: Pose with Node Concat :  Batch Ind: 5\n",
      "Node: Pose with Node Concat :  Batch Ind: 6\n",
      "Node: Pose with Node Concat :  Batch Ind: 7\n",
      "Node: Pose with Node Concat :  Batch Ind: 8\n",
      "Node: Pose with Node Concat :  Batch Ind: 9\n",
      "Node: Pose with Node Concat :  Batch Ind: 10\n",
      "Node: Pose with Node Concat :  Batch Ind: 11\n",
      "Node: Pose with Node Concat :  Batch Ind: 12\n",
      "Node: Pose with Node Concat :  Batch Ind: 13\n",
      "Node: Pose with Node Concat :  Batch Ind: 14\n",
      "Node: Pose with Node Concat :  Batch Ind: 15\n",
      "Node: Transformation:  Batch Ind: 0\n",
      "Node: Transformation:  Batch Ind: 1\n",
      "Node: Transformation:  Batch Ind: 2\n",
      "Node: Transformation:  Batch Ind: 3\n",
      "Node: Transformation:  Batch Ind: 4\n",
      "Node: Transformation:  Batch Ind: 5\n",
      "Node: Transformation:  Batch Ind: 6\n",
      "Node: Transformation:  Batch Ind: 7\n",
      "Node: Transformation:  Batch Ind: 8\n",
      "Node: Transformation:  Batch Ind: 9\n",
      "Node: Transformation:  Batch Ind: 10\n",
      "Node: Transformation:  Batch Ind: 11\n",
      "Node: Transformation:  Batch Ind: 12\n",
      "Node: Transformation:  Batch Ind: 13\n",
      "Node: Transformation:  Batch Ind: 14\n",
      "Node: Transformation:  Batch Ind: 15\n",
      "Epoch: [0][   0/1719]\tTime  5.600 ( 5.600)\tData  5.384 ( 5.384)\tLoss 9.6645e+00 (9.6645e+00)\tAcc@Inst   0.00 (  0.00)\tAcc@Proto   0.00 (  0.00)\n",
      "Logging to TB....\n"
     ]
    }
   ],
   "source": [
    "run_training(default_args=\"--exp-dir test_run\".split())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disco",
   "language": "python",
   "name": "disco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
