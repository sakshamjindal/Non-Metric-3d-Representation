{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from random import sample\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from core.model.encoder import Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from core.dataloader import CLEVR_train, collate_boxes, CLEVR_train_onlyquery, collate_boxes_onlyquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised..... 4267  files...\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CLEVR_train(root_dir='/home/mprabhud/dataset/clevr_lang/npys/aa_5t.txt')\n",
    "train_loader = DataLoader(train_dataset, batch_size=5, shuffle=True, collate_fn=collate_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in train_loader:\n",
    "    feed_dict_q_, feed_dict_k_, metadata_ = b\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict_q_[\"images\"] = feed_dict_q_[\"images\"].cuda()\n",
    "feed_dict_k_[\"images\"] = feed_dict_k_[\"images\"].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "\n",
    "class MoCo(nn.Module):\n",
    "    \"\"\"\n",
    "    Build a MoCo model with: a query encoder, a key encoder, and a queue\n",
    "    https://arxiv.org/abs/1911.05722\n",
    "    \"\"\"\n",
    "    def __init__(self, base_encoder=None, dim=256, r=35, m=0.999, T=0.1, mlp=False):\n",
    "        \"\"\"\n",
    "        dim: feature dimension (default: 128)\n",
    "        r: queue size; number of negative samples/prototypes (default: 16384)\n",
    "        m: momentum for updating key encoder (default: 0.999)\n",
    "        T: softmax temperature \n",
    "        mlp: whether to use mlp projection\n",
    "        \"\"\"\n",
    "        super(MoCo, self).__init__()\n",
    "\n",
    "        self.r = r\n",
    "        self.m = m\n",
    "        self.T = T\n",
    "        \n",
    "\n",
    "        # create the encoders\n",
    "        # num_classes is the output fc dimension\n",
    "#         self.encoder_q = base_encoder(num_classes=dim)\n",
    "#         self.encoder_k = base_encoder(num_classes=dim)\n",
    "\n",
    "#         if mlp:  # hack: brute-force replacement\n",
    "#             dim_mlp = self.encoder_q.fc.weight.shape[1]\n",
    "#             self.encoder_q.fc = nn.Sequential(nn.Linear(dim_mlp, dim_mlp), nn.ReLU(), self.encoder_q.fc)\n",
    "#             self.encoder_k.fc = nn.Sequential(nn.Linear(dim_mlp, dim_mlp), nn.ReLU(), self.encoder_k.fc)\n",
    "\n",
    "        self.encoder_q = Encoder(dim = dim)\n",
    "        self.encoder_k = Encoder(dim = dim)\n",
    "\n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data.copy_(param_q.data)  # initialize\n",
    "            param_k.requires_grad = False  # not update by gradient\n",
    "\n",
    "        # create the queue\n",
    "        self.register_buffer(\"queue\", torch.randn(dim, r))\n",
    "        self.queue = nn.functional.normalize(self.queue, dim=0)\n",
    "\n",
    "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _momentum_update_key_encoder(self):\n",
    "        \"\"\"\n",
    "        Momentum update of the key encoder\n",
    "        \"\"\"\n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data = param_k.data * self.m + param_q.data * (1. - self.m)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue(self, keys):\n",
    "\n",
    "        # gather keys before updating queue\n",
    "#         keys = concat_all_gather(keys)\n",
    "\n",
    "        batch_size = keys.shape[0]\n",
    "\n",
    "        ptr = int(self.queue_ptr)\n",
    "        #removes for now\n",
    "#         assert self.r % batch_size == 0  # for simplicity\n",
    "\n",
    "        # replace the keys at ptr (dequeue and enqueue)\n",
    "        self.queue[:, ptr:ptr + batch_size] = keys.T\n",
    "        ptr = (ptr + batch_size) % self.r  # move pointer\n",
    "\n",
    "        self.queue_ptr[0] = ptr\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _batch_shuffle_ddp(self, x):\n",
    "        \"\"\"\n",
    "        Batch shuffle, for making use of BatchNorm.\n",
    "        *** Only support DistributedDataParallel (DDP) model. ***\n",
    "        \"\"\"\n",
    "        # gather from all gpus\n",
    "        batch_size_this = x.shape[0]\n",
    "        x_gather = concat_all_gather(x)\n",
    "        batch_size_all = x_gather.shape[0]\n",
    "\n",
    "        num_gpus = batch_size_all // batch_size_this\n",
    "\n",
    "        # random shuffle index\n",
    "        idx_shuffle = torch.randperm(batch_size_all).cuda()\n",
    "\n",
    "        # broadcast to all gpus\n",
    "        torch.distributed.broadcast(idx_shuffle, src=0)\n",
    "\n",
    "        # index for restoring\n",
    "        idx_unshuffle = torch.argsort(idx_shuffle)\n",
    "\n",
    "        # shuffled index for this gpu\n",
    "        gpu_idx = torch.distributed.get_rank()\n",
    "        idx_this = idx_shuffle.view(num_gpus, -1)[gpu_idx]\n",
    "\n",
    "        return x_gather[idx_this], idx_unshuffle\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _batch_unshuffle_ddp(self, x, idx_unshuffle):\n",
    "        \"\"\"\n",
    "        Undo batch shuffle.\n",
    "        *** Only support DistributedDataParallel (DDP) model. ***\n",
    "        \"\"\"\n",
    "        # gather from all gpus\n",
    "        batch_size_this = x.shape[0]\n",
    "        x_gather = concat_all_gather(x)\n",
    "        batch_size_all = x_gather.shape[0]\n",
    "\n",
    "        num_gpus = batch_size_all // batch_size_this\n",
    "\n",
    "        # restored index for this gpu\n",
    "        gpu_idx = torch.distributed.get_rank()\n",
    "        idx_this = idx_unshuffle.view(num_gpus, -1)[gpu_idx]\n",
    "\n",
    "        return x_gather[idx_this]\n",
    "\n",
    "    def forward(self, feed_dict_q, feed_dict_k=None, metadata=None, is_eval=False, cluster_result=None, index=None, mode=\"node\"):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            feed_dict_q: a batch of query images and bounding boxes\n",
    "            feed_dict_k: a batch of key images and bounding boxes\n",
    "            is_eval: return momentum embeddings (used for clustering)\n",
    "            cluster_result: cluster assignments, centroids, and density\n",
    "            index: indices for training samples\n",
    "            mode : should be either 'node' or 'spatial' depending on whether training for node or spatial embeddings\n",
    "        Output:\n",
    "            logits, targets, proto_logits, proto_targets\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        if mode==\"node\":\n",
    "            rel_viewpoint=None\n",
    "            \n",
    "        \n",
    "        if is_eval:\n",
    "            _, k = self.encoder_k(feed_dict_q, mode) \n",
    "            k = nn.functional.normalize(k, dim=1)            \n",
    "            return k\n",
    "        \n",
    "        rel_viewpoint = metadata[\"rel_viewpoint\"]\n",
    "        \n",
    "        if mode==\"node\":\n",
    "            rel_viewpoint=None\n",
    "        \n",
    "        # compute key features\n",
    "        with torch.no_grad():  # no gradient to keys\n",
    "            self._momentum_update_key_encoder()  # update the key encoder\n",
    "\n",
    "#             # shuffle for making use of BN\n",
    "#             im_k, idx_unshuffle = self._batch_shuffle_ddp(im_k)\n",
    "\n",
    "            _, k = self.encoder_k(feed_dict_k, mode, rel_viewpoint)  # keys: NxC\n",
    "            k = nn.functional.normalize(k, dim=1)    # not needed scene graph does that already\n",
    "\n",
    "#             # undo shuffle\n",
    "#             k = self._batch_unshuffle_ddp(k, idx_unshuffle)\n",
    "\n",
    "        # compute query features\n",
    "        _, q = self.encoder_q(feed_dict_q, mode)  # queries: NxC\n",
    "        q = nn.functional.normalize(q, dim=1)\n",
    "        \n",
    "        # add to pool\n",
    "        \n",
    "        \n",
    "        # compute logits\n",
    "        # Einstein sum is more intuitive\n",
    "        # positive logits: Nx1\n",
    "        l_pos = torch.einsum('nc,nc->n', [q, k]).unsqueeze(-1)\n",
    "        # negative logits: Nxr\n",
    "        l_neg = torch.einsum('nc,ck->nk', [q, self.queue.clone().detach()])\n",
    "\n",
    "        # logits: Nx(1+r)\n",
    "        logits = torch.cat([l_pos, l_neg], dim=1)\n",
    "\n",
    "        # apply temperature\n",
    "        logits /= self.T\n",
    "\n",
    "        # labels: positive key indicators\n",
    "        labels = torch.zeros(logits.shape[0], dtype=torch.long).cuda()\n",
    "\n",
    "        # dequeue and enqueue\n",
    "        self._dequeue_and_enqueue(k)\n",
    "        \n",
    "        # prototypical contrast\n",
    "        if cluster_result is not None:  \n",
    "            proto_labels = []\n",
    "            proto_logits = []\n",
    "            for n, (im2cluster,prototypes,density) in enumerate(zip(cluster_result['im2cluster'],cluster_result['centroids'],cluster_result['density'])):\n",
    "                # get positive prototypes\n",
    "                pos_proto_id = im2cluster[index]\n",
    "                pos_prototypes = prototypes[pos_proto_id]    \n",
    "                \n",
    "                # sample negative prototypes\n",
    "                all_proto_id = [i for i in range(im2cluster.max())] \n",
    "                \n",
    "                #print(len(pos_prototypes), len(all_proto_id))\n",
    "                neg_proto_id = set(all_proto_id)-set(pos_proto_id.tolist())\n",
    "                neg_proto_id = sample(neg_proto_id,self.r) #sample r negative prototypes \n",
    "                neg_prototypes = prototypes[neg_proto_id]    \n",
    "\n",
    "                proto_selected = torch.cat([pos_prototypes,neg_prototypes],dim=0)\n",
    "                \n",
    "                # compute prototypical logits\n",
    "                logits_proto = torch.mm(q,proto_selected.t())\n",
    "                \n",
    "                # targets for prototype assignment\n",
    "                labels_proto = torch.linspace(0, q.size(0)-1, steps=q.size(0)).long().cuda()\n",
    "                \n",
    "                # scaling temperatures for the selected prototypes\n",
    "                temp_proto = density[torch.cat([pos_proto_id,torch.LongTensor(neg_proto_id).cuda()],dim=0)]  \n",
    "                logits_proto /= temp_proto\n",
    "                \n",
    "                proto_labels.append(labels_proto)\n",
    "                proto_logits.append(logits_proto)\n",
    "            return logits, labels, proto_logits, proto_labels\n",
    "        else:\n",
    "            return logits, labels, None, None\n",
    "\n",
    "\n",
    "# utils\n",
    "@torch.no_grad()\n",
    "def concat_all_gather(tensor):\n",
    "    \"\"\"\n",
    "    Performs all_gather operation on the provided tensors.\n",
    "    *** Warning ***: torch.distributed.all_gather has no gradient.\n",
    "    \"\"\"\n",
    "    tensors_gather = [torch.ones_like(tensor)\n",
    "        for _ in range(torch.distributed.get_world_size())]\n",
    "    torch.distributed.all_gather(tensors_gather, tensor, async_op=False)\n",
    "\n",
    "    output = torch.cat(tensors_gather, dim=0)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MoCo()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the MoCo model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(feed_dict_q_, feed_dict_k_, metadata_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5.4730e+00,  1.3212e+00,  4.5521e-01,  1.7813e-01, -7.5497e-01,\n",
       "          -4.5264e-01, -1.8286e-01, -4.7412e-01,  3.1932e-01, -2.0586e-01,\n",
       "           6.7381e-02, -1.0405e+00, -6.6116e-01,  9.4359e-01,  5.1845e-02,\n",
       "           2.7534e-01,  3.4428e-01,  1.1851e+00, -1.1352e+00, -5.2477e-01,\n",
       "          -2.7305e-01, -9.1922e-02, -9.0147e-01,  4.1309e-01,  8.1592e-01,\n",
       "           5.4017e-01,  1.5650e-01,  7.9309e-01,  6.5606e-01,  8.7867e-01,\n",
       "          -7.5719e-02, -1.8141e-01, -3.6014e-03,  8.6030e-01,  1.0833e+00,\n",
       "          -5.7155e-01, -2.3005e-02, -4.6413e-01, -4.5147e-01,  2.5380e-01,\n",
       "          -1.0389e+00,  4.6751e-01, -5.1649e-01, -1.0491e+00, -4.1829e-01,\n",
       "           1.6555e-01,  5.5656e-01, -3.8227e-01, -8.8586e-01, -3.4083e-01,\n",
       "          -7.4026e-01,  3.2186e-01, -8.9555e-01,  4.7623e-02,  2.3613e-01,\n",
       "           1.2798e+00,  8.3553e-01, -2.5894e-01,  9.8904e-01,  1.1295e-01,\n",
       "           6.9195e-02, -5.1361e-01,  5.5174e-01, -3.1188e-01, -4.8423e-01,\n",
       "          -1.5440e-01,  1.1071e+00, -3.6743e-01, -2.8760e-02,  9.3248e-02,\n",
       "          -7.4964e-01, -8.6030e-02, -2.3879e-01,  3.8640e-02,  3.2903e-03,\n",
       "           5.7966e-02,  7.0984e-01,  3.6805e-01,  4.6559e-01,  1.8570e-01,\n",
       "          -9.5505e-01,  7.2943e-01, -6.8068e-01,  5.1783e-01, -9.2967e-01,\n",
       "           2.6428e-01,  4.3954e-01,  5.8257e-01, -9.0572e-01,  7.3834e-01,\n",
       "           1.0375e+00,  1.8058e-01, -3.6482e-01, -6.0992e-01,  8.2869e-02,\n",
       "           7.4151e-01,  8.2076e-02,  9.6500e-01,  6.0182e-01,  4.0164e-01,\n",
       "           5.7511e-01, -2.4897e-01, -4.7929e-01,  9.5067e-01,  8.0056e-01,\n",
       "           1.0131e+00, -8.4398e-01,  9.7188e-01,  8.3913e-01,  7.5014e-01,\n",
       "          -1.2070e-01, -1.9679e-01,  9.0173e-01, -2.9491e-02, -4.4141e-01,\n",
       "           5.4870e-01,  2.8752e-01, -1.2650e-01, -9.6565e-01,  8.0896e-02,\n",
       "           6.8846e-01],\n",
       "         [ 6.6231e+00,  1.3123e+00,  2.6427e-01, -2.0425e-01, -4.6594e-01,\n",
       "          -4.5387e-02,  2.0914e-01, -3.4715e-01, -2.0611e-01, -8.7485e-01,\n",
       "           5.0865e-02, -7.8921e-01, -3.7638e-01, -4.4107e-01, -2.4249e-02,\n",
       "           4.3681e-01,  8.8868e-02,  2.0047e-01, -1.5963e+00, -2.8423e-01,\n",
       "           1.3520e-01,  1.6155e-01, -6.5336e-01, -3.5187e-02,  1.0466e+00,\n",
       "           6.1006e-01,  7.0204e-01,  9.3703e-01,  7.4457e-01,  1.3070e+00,\n",
       "          -3.8210e-01,  1.8279e-02, -1.0452e-01, -4.2832e-01,  6.1395e-01,\n",
       "          -4.2102e-01,  9.4744e-01, -6.0459e-01, -1.7457e-02,  1.3464e-02,\n",
       "          -1.0864e+00,  1.4824e+00, -9.8417e-01, -8.8438e-01, -1.8902e-01,\n",
       "           3.7299e-01,  6.5782e-01, -6.2337e-01, -2.5527e-01,  1.9575e-01,\n",
       "          -1.1716e+00,  3.0580e-02, -4.4419e-01,  5.2420e-01, -6.2259e-01,\n",
       "           1.1569e+00,  1.1755e+00,  4.7389e-01,  8.9251e-01, -9.6745e-01,\n",
       "           3.7903e-01, -6.6418e-01,  2.3591e-01,  2.2345e-01, -4.3525e-01,\n",
       "          -7.5896e-01, -1.5399e-02,  4.7704e-01, -4.6769e-01, -3.1229e-01,\n",
       "           3.9866e-02,  2.2774e-01,  5.3937e-01,  6.2381e-02,  7.3309e-01,\n",
       "          -1.6323e-01,  7.7810e-01, -3.0984e-01, -6.6963e-01,  6.4615e-01,\n",
       "          -1.0465e+00,  3.2877e-01, -9.8808e-01, -4.2758e-01, -4.3888e-01,\n",
       "           4.2296e-01, -4.2494e-01,  3.2401e-01, -1.1659e+00,  8.0335e-01,\n",
       "           6.3352e-01,  1.1210e+00,  2.3894e-01, -5.1120e-01,  6.1819e-01,\n",
       "           3.5646e-01,  3.6646e-01,  2.6489e-01,  2.4890e-01,  5.3251e-01,\n",
       "           4.7735e-01, -8.5709e-01,  3.0937e-01,  5.7867e-01,  9.3528e-01,\n",
       "           1.2580e+00, -9.1816e-01,  1.1004e-01,  1.0304e+00,  3.9163e-01,\n",
       "          -6.0126e-01,  8.2196e-02,  3.0922e-02,  3.7445e-01, -6.3949e-01,\n",
       "          -7.5125e-02,  1.7918e-01,  8.6221e-01, -1.1857e+00, -6.4145e-02,\n",
       "           7.0580e-01],\n",
       "         [ 5.0838e+00,  9.2018e-01,  2.5306e-01, -1.1701e-01,  1.1412e-01,\n",
       "          -1.2288e-01,  3.1073e-01, -5.0888e-01,  2.6009e-01, -5.4112e-01,\n",
       "          -1.0395e-01, -4.3566e-01,  2.5793e-03,  3.7728e-01,  2.4491e-01,\n",
       "          -5.8100e-01,  6.9535e-02,  5.3702e-01, -1.4239e+00, -5.9319e-01,\n",
       "           5.6459e-02,  7.7959e-01, -3.9311e-01, -5.3026e-01,  6.1602e-01,\n",
       "          -7.2847e-01,  1.6895e-01,  6.7757e-01,  6.6661e-01,  8.1877e-02,\n",
       "           9.4293e-02,  1.3289e-01, -4.4362e-01, -3.1184e-01,  1.4323e-01,\n",
       "          -3.5498e-01,  2.5971e-01,  6.9463e-04,  1.4630e-01, -5.7952e-02,\n",
       "          -6.6177e-01,  3.2099e-01, -9.3278e-01, -9.1650e-01,  1.3763e-01,\n",
       "          -4.3623e-01,  2.0894e-01, -5.3078e-02, -5.9163e-01, -3.3210e-01,\n",
       "           1.8484e-01,  5.3732e-01,  4.2734e-01,  2.4330e-01, -9.2123e-01,\n",
       "           5.4441e-01,  8.4054e-01,  3.8348e-02, -1.6218e-01, -3.0973e-01,\n",
       "           2.4817e-01, -3.2857e-01, -2.8804e-01,  5.0466e-01, -3.5642e-01,\n",
       "          -7.8183e-01,  2.9668e-01, -1.6858e-02, -2.2828e-01, -9.2958e-01,\n",
       "           9.5115e-02, -3.7652e-01,  2.1528e-01, -4.0127e-01, -3.8878e-01,\n",
       "          -3.4822e-01,  1.2772e+00,  1.2410e-01, -3.4644e-01,  4.0130e-01,\n",
       "          -1.8812e-01,  1.0502e+00, -9.0098e-01, -1.5654e-01, -1.3030e+00,\n",
       "           8.7547e-01,  5.2008e-02,  7.5939e-01, -7.8481e-01,  8.0255e-01,\n",
       "           6.7841e-01,  5.0645e-01, -3.4047e-01, -3.0884e-01,  1.7544e-01,\n",
       "           1.1778e+00, -3.8373e-01,  5.2070e-01,  6.3533e-02,  7.2934e-01,\n",
       "           1.1716e+00,  1.0086e-01,  1.3760e-02,  4.9719e-01,  2.7983e-01,\n",
       "           1.2274e+00, -1.5610e+00,  9.2110e-02,  5.3480e-01,  4.4905e-01,\n",
       "           8.4148e-02,  6.9909e-01,  4.3615e-02, -3.9254e-01, -1.6846e-01,\n",
       "           8.0352e-01,  2.2152e-01,  8.7948e-01, -7.9783e-01, -3.6391e-02,\n",
       "           9.6260e-01],\n",
       "         [ 5.7886e+00,  7.6792e-01,  1.2041e-01, -3.1093e-01, -2.1476e-01,\n",
       "          -6.1367e-01,  3.4405e-01, -8.3207e-01,  2.7670e-02, -7.6082e-01,\n",
       "           1.2171e-01, -4.0542e-01,  1.2394e-01,  5.8149e-01,  6.6923e-02,\n",
       "           5.2398e-01, -1.9220e-01,  1.2972e-01, -1.1124e+00,  1.3952e-02,\n",
       "          -1.0304e-01,  1.0116e-01, -1.0738e+00, -8.0933e-01,  1.4491e+00,\n",
       "          -1.5539e-01,  7.3137e-01,  5.0635e-01,  1.0021e+00,  8.4287e-01,\n",
       "          -6.1213e-01,  1.9283e-01,  2.3530e-01,  2.9293e-02,  5.4347e-01,\n",
       "          -5.2700e-01,  6.4912e-01, -3.9779e-01, -3.9637e-01,  3.2873e-01,\n",
       "          -3.1426e-01,  1.0900e+00, -5.5539e-01, -7.8969e-01,  3.1876e-02,\n",
       "          -2.5781e-01,  6.5959e-01, -5.3809e-01, -2.7609e-01,  2.9801e-01,\n",
       "          -3.9136e-01, -5.3027e-01, -7.0756e-01,  5.1855e-01, -1.6294e-01,\n",
       "           1.3087e+00, -5.6182e-02,  5.0613e-01,  1.3432e+00, -9.4421e-01,\n",
       "          -3.3411e-01, -4.5263e-01,  1.7169e-01,  7.5866e-01, -4.3162e-01,\n",
       "          -4.3434e-01,  1.1929e-01,  5.8359e-01, -5.2295e-01, -8.9982e-01,\n",
       "           4.1189e-02, -9.6450e-02, -6.8234e-01,  9.6839e-03,  6.3698e-01,\n",
       "           3.4705e-01,  9.1476e-01, -3.9742e-01, -2.3711e-01,  1.0627e+00,\n",
       "          -7.2044e-01,  8.6919e-01, -9.3737e-01, -3.2118e-01, -6.8435e-01,\n",
       "           4.2540e-01, -1.6500e-01,  1.9606e-01, -3.0875e-01,  1.9014e-01,\n",
       "           9.3104e-01,  6.0918e-01,  4.8072e-01, -9.5763e-01,  3.4423e-01,\n",
       "           4.5768e-01,  7.9914e-02,  3.2833e-01,  4.9012e-01, -1.7765e-03,\n",
       "           5.7736e-01, -2.8913e-01,  6.9722e-01,  6.5958e-01,  6.1976e-01,\n",
       "           1.0477e+00, -1.4941e+00, -5.6984e-02,  8.9781e-01,  8.9938e-02,\n",
       "          -5.6391e-01,  6.4209e-01,  2.1360e-01, -1.7597e-01, -1.6832e-01,\n",
       "           6.0464e-01,  8.3832e-01,  7.6388e-01, -8.1488e-01, -1.2935e-01,\n",
       "           7.8596e-01],\n",
       "         [ 7.8554e+00,  1.1071e+00,  3.0410e-01, -1.1184e-01,  3.8288e-01,\n",
       "           6.9441e-03, -1.7178e-01, -3.6629e-02,  3.3579e-01, -9.1197e-01,\n",
       "          -8.8970e-01,  8.1103e-02,  7.9747e-01,  6.1769e-01, -1.5331e-01,\n",
       "           1.7895e-01,  2.7983e-01,  1.2933e-01, -1.3624e+00, -2.7286e-01,\n",
       "           5.3124e-01, -3.0701e-01, -5.5788e-01, -2.1278e-01,  1.4665e+00,\n",
       "           1.9686e-01, -1.4156e-01,  2.7819e-01,  1.7512e-01,  2.0522e+00,\n",
       "          -3.2104e-01, -2.7071e-01,  1.4520e-01,  8.4421e-01,  6.8096e-01,\n",
       "          -2.7044e-01, -2.1335e-03, -1.4656e+00,  2.2965e-01, -7.6376e-02,\n",
       "          -7.4706e-01,  8.5246e-01, -4.1428e-01, -2.4394e-01, -8.6454e-01,\n",
       "           7.8937e-01,  1.1378e+00,  4.9396e-01, -1.0734e-01,  3.7287e-01,\n",
       "          -1.1618e+00, -5.9722e-01, -1.2730e-01,  8.7092e-02, -3.8577e-01,\n",
       "           8.7271e-01,  3.4288e-01,  8.5250e-01,  6.5956e-01, -4.9053e-01,\n",
       "           4.5647e-01, -3.0603e-01,  2.9627e-01, -8.6398e-02, -2.5342e-01,\n",
       "           1.0051e-01,  2.5922e-01,  1.4914e-01, -4.0391e-01, -5.0375e-01,\n",
       "          -1.4931e-01, -1.2685e-01,  3.0828e-01,  4.5265e-01,  6.1065e-01,\n",
       "          -9.6800e-01, -4.2657e-02,  4.6521e-01, -7.0182e-01,  1.0685e+00,\n",
       "          -7.7895e-01,  8.9270e-01, -9.9012e-01, -1.2583e-01, -2.7721e-01,\n",
       "          -1.1954e-01,  2.3968e-01,  3.4196e-01, -8.9147e-01,  2.3218e-01,\n",
       "           9.4745e-01,  7.0081e-01, -4.3336e-02, -4.3511e-01,  7.0183e-01,\n",
       "           3.7495e-01,  1.7920e-01,  8.5652e-01,  5.5830e-01, -2.4806e-01,\n",
       "           6.7064e-01, -7.2826e-01, -2.5929e-01,  6.1916e-01,  1.1321e+00,\n",
       "           2.3300e-01, -3.1610e-01,  8.4652e-01,  1.1653e+00,  1.0772e+00,\n",
       "          -6.9935e-01, -8.3202e-02,  1.2760e+00,  9.5330e-01, -1.2611e+00,\n",
       "          -1.3641e-01,  1.1872e-01, -9.8718e-02, -2.3125e-01, -5.5142e-02,\n",
       "           4.2099e-02]], device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor([0, 0, 0, 0, 0], device='cuda:0'),\n",
       " None,\n",
       " None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, labels, _, __ = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 121]), torch.Size([5]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disco",
   "language": "python",
   "name": "disco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
